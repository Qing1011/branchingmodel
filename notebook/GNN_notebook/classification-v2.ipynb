{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045a21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, NNConv, global_mean_pool, TopKPooling\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat, savemat\n",
    "import pandas as pd\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA\n",
    "import copy\n",
    "import math\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "import numpy.linalg as LA\n",
    "import gzip\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# load pickle module\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = 2.5\n",
    "rs = np.array([20, 10, 2.0, 1.0, 0.5, 0.2, 0.1, 0.05, 0.025, 5.   ,  2.5  , 13.333,  3.333,  1.333,  0.667,  0.286,  0.133,\n",
    "        0.067,  0.033, 0.37,7.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba100251",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382076f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.        , 30.3030303 , 20.        , 14.92537313, 10.        ,\n",
       "        7.51879699,  5.        ,  3.4965035 ,  2.7027027 ,  2.        ,\n",
       "        1.49925037,  1.        ,  0.75018755,  0.5       ,  0.4       ,\n",
       "        0.30003   ,  0.2       ,  0.13513514,  0.1       ,  0.07500188,\n",
       "        0.05      ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd4b2abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x29e641510>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(rs,rs)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.axhline(5)\n",
    "# plt.axhline(0.5)\n",
    "# plt.axhline(0.1)\n",
    "plt.axvline(5)\n",
    "plt.axvline(0.5)\n",
    "plt.axvline(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56b6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "WN = np.loadtxt('../W_avg.csv') ### numpy arrary\n",
    "WN2 = np.dot(WN, WN)\n",
    "# prob = WN[:,1858]\n",
    "prob = WN2[:,1858]\n",
    "prob_2d = prob.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fbbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_s = nx.from_numpy_array(WN)\n",
    "edges = np.array(g_s.edges()).transpose()\n",
    "edge_index = torch.tensor(edges,dtype = torch.int64)\n",
    "# edge_weight = torch.tensor(WN[edge_index[0], edge_index[1]], dtype=torch.float)\n",
    "edge_weights = []\n",
    "for (u, v) in g_s.edges():\n",
    "    edge_weights.append([g_s[u][v]['weight']])\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc84482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gzipped_numpy(filename):\n",
    "    try:\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            return np.load(f, allow_pickle=True)\n",
    "    except FileNotFoundError:\n",
    "        return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d805fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3, \n",
    "           5.0:1 ,  2.5:1  , 13.333:0,  3.333:1,  1.333:1,  0.667:1,  0.286:2,  0.133:2,\n",
    "        0.067:3,  0.033:3, 0.37:2,7.4:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0087b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025 3\n",
      "0.033 3\n",
      "0.05 3\n",
      "0.067 3\n",
      "0.1 2\n",
      "0.133 2\n",
      "0.2 2\n",
      "0.286 2\n",
      "0.37 2\n",
      "0.5 1\n",
      "0.667 1\n",
      "1.0 1\n",
      "1.333 1\n",
      "2.0 1\n",
      "2.5 1\n",
      "3.333 1\n",
      "5.0 1\n",
      "7.4 0\n",
      "10.0 0\n",
      "13.333 0\n",
      "20.0 0\n"
     ]
    }
   ],
   "source": [
    "export_dir = '/Users/qingyao/Documents/branching_data/simulation/python_cutoff_addno/'\n",
    "#### data preparation\n",
    "dataset = []\n",
    "# r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3}\n",
    "\n",
    "for r_idx in range(21):\n",
    "    r = rs[r_idx]\n",
    "    sub_export_dir = export_dir+'branching_R0-{}_r-{}/'.format(np.round(R0,2),np.round(r,3))\n",
    "    r_c = r_class[r]\n",
    "    print(r, r_c)\n",
    "    # Create a list to hold our Data objects\n",
    "    for g_idx in range(300):\n",
    "        export_names = sub_export_dir+'NewInf_R0-{}_r-{}_{}.npy.gz'.format(np.round(R0,2),np.round(r,3),(g_idx+1))\n",
    "        g_i = load_gzipped_numpy(export_names)\n",
    "#         g_i_new = np.hstack((g_i[:,10:], prob_2d))\n",
    "        g_i_new = g_i[:,10:]*prob_2d\n",
    "        matrix = torch.from_numpy(g_i_new)\n",
    "\n",
    "        y = torch.tensor([r_c], dtype=torch.long)\n",
    "        # Create a Data object for each graph\n",
    "        data = Data(x=matrix, edge_index=edge_index, edge_attr=edge_weights,y=y)\n",
    "        data.x = data.x.float()\n",
    "#         data.y = data.y.long()\n",
    "        # Add the Data object to our list\n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3079dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "all_data_len = len(dataset)\n",
    "train_data, test_data = random_split(dataset, [int(all_data_len*0.8), int(all_data_len*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41143989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingyao/anaconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Epoch: 001, Loss: 1.3537:   1%|▏               | 1/90 [00:54<1:20:08, 54.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.35370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 1.3268:   2%|▎               | 2/90 [01:48<1:19:33, 54.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 1.32677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 1.3068:   3%|▌               | 3/90 [02:42<1:18:40, 54.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 1.30684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 1.2542:   4%|▋               | 4/90 [03:37<1:18:00, 54.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 1.25423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 1.3201:   6%|▉               | 5/90 [04:31<1:16:49, 54.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 1.32007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 1.1708:   7%|█               | 6/90 [05:25<1:15:48, 54.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 1.17080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 1.2726:   8%|█▏              | 7/90 [06:19<1:14:59, 54.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 1.27262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 1.2568:   9%|█▍              | 8/90 [07:13<1:13:50, 54.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 1.25683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 1.3367:  10%|█▌              | 9/90 [08:07<1:12:57, 54.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 1.33669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.3299:  11%|█▋             | 10/90 [09:01<1:11:59, 53.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.32993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss: 1.3267:  12%|█▊             | 11/90 [09:55<1:11:18, 54.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss: 1.32674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss: 1.3195:  13%|██             | 12/90 [10:44<1:08:13, 52.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss: 1.31945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 1.3053:  14%|██▏            | 13/90 [11:27<1:03:32, 49.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 1.30527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss: 1.2987:  16%|██▎            | 14/90 [12:09<1:00:04, 47.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss: 1.29867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 1.3485:  17%|██▊              | 15/90 [12:52<57:27, 45.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 1.34845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss: 1.3151:  18%|███              | 16/90 [13:34<55:23, 44.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss: 1.31508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 016, Loss: 1.3151:  18%|██▋            | 16/90 [14:17<1:06:05, 53.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss: 1.45791\n",
      "\n",
      " Stopped early at epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module): ### the simpliest model that GNN and it is classical, used as baseline\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 128)        \n",
    "        self.conv2 = GCNConv(128, 64) \n",
    "        self.conv3 = GCNConv(64, 16) \n",
    "        self.conv4 = GCNConv(16, 8) \n",
    "        self.classifier = Linear(8, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        edge_index, edge_weight = add_self_loops(edge_index, edge_attr=edge_weight, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv4(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Now we can create a DataLoader\n",
    "myloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "# Create a model and an optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(num_node_features=50, num_classes=4).to(device) ### only look at the last 30 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train(model, optimizer, loader):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    total = 0\n",
    "    results = []\n",
    "    for data in myloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        output = model(data) \n",
    "        label = data.y.to(device)\n",
    "        y_true.append(label)\n",
    "        loss = F.cross_entropy(output, label)     \n",
    "        loss.backward() \n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step() \n",
    "        \n",
    "        results.append(output)\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)  \n",
    "        total += label.size(0)  \n",
    "        correct += (predicted == label).sum().item()  \n",
    "    accuracy = 100 * correct / total\n",
    "    return loss_all / len(myloader.dataset), accuracy, results, y_true\n",
    "\n",
    "counter = 0\n",
    "count_epochs = 0\n",
    "best = float(\"inf\")\n",
    "epochs = 90\n",
    "patience = 10\n",
    "loss_ep= []\n",
    "ac_ep = []\n",
    " \n",
    "for epoch in (pbar := tqdm(range(1, epochs + 1))):\n",
    "    loss, ac, myres, reals = train(model, optimizer, myloader)\n",
    "    loss_ep.append(loss)\n",
    "    ac_ep.append(ac)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, loss))\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        count_epochs += 1\n",
    "        \n",
    "    if counter > patience:\n",
    "        break\n",
    "        # print(f\"Epoch: {​​​​​​epoch:03d}​​​​​​, Loss: {​​​​​​loss:.4f}​​​​​​\")\n",
    "#     scheduler.step()\n",
    "    pbar.set_description(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}\")\n",
    "print(\"\\n\", \"Stopped early at epoch: \", count_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b06357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_test = []\n",
    "    y_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data, label = data.to(device), data.y.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = F.cross_entropy(output, label)\n",
    "            test_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            # Convert label to one-hot encoding\n",
    "            one_hot_label = torch.zeros(label.size(0), 4).to(device)  # assuming 4 classes\n",
    "            one_hot_label.scatter_(1, label.unsqueeze(1), 1)  # in-place operation to convert to one-hot\n",
    "            y_test.extend(one_hot_label.cpu().numpy().tolist())\n",
    "            \n",
    "            # Store the scores\n",
    "            y_scores.extend(output.cpu().numpy().tolist())\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = output.max(1)\n",
    "            total += label.size(0)\n",
    "            correct += predicted.eq(label).sum().item()\n",
    "\n",
    "    avg_loss = test_loss / total\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Test set: Average loss: {avg_loss:.4f}, Accuracy: {correct}/{total} ({accuracy:.2f}%)\")\n",
    "\n",
    "    return avg_loss, accuracy, y_test, y_scores\n",
    "\n",
    "# Assuming you have a test_loader, model, and criterion already defined\n",
    "test_loss, test_accuracy, y_test, y_score = test(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df228d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "n_classes = 4\n",
    "colors = {0:'orange',1:'yellowgreen',2:'lightskyblue',3:'cornflowerblue'}\n",
    "labels = {0:r'LS: $r > 5$',1:r'MS: $r \\in [0.5,5]$',2:r'HS: $r \\in [0.1,0.5)$',3:r'ES: $r<0.1$'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = np.array([[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1], [1,0,0,0]])\n",
    "# y_score = np.array([[0.5,0.2,0.1,0.2], [0.1,0.5,0.2,0.2], [0.2,0.1,0.5,0.2], [0.2,0.1,0.2,0.5], [0.6,0.1,0.1,0.2]])\n",
    "\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "y_score = np.array(y_score)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "\n",
    "# smoothed_fpr = dict()\n",
    "# smoothed_tpr = dict()\n",
    "\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "#     smoothed_tpr[i] = moving_average(tpr[i], 5)\n",
    "#     smoothed_fpr[i] = moving_average(fpr[i], 5)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.rcParams['font.family'] = 'Times New Roman' \n",
    "plt.figure(dpi=600,figsize=(3.5,2.5))\n",
    "for i in range(n_classes):\n",
    "#     plt.plot(smoothed_fpr[i], smoothed_tpr[i], color = colors[i],\n",
    "#              label='Class {0} (area = {1:0.2f})'.format(labels[i], roc_auc[i]))\n",
    "    plt.plot(fpr[i], tpr[i], color = colors[i],\n",
    "             label='{0} (AUC = {1:0.2f})'.format(labels[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--',lw=0.5)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',size=8)\n",
    "plt.ylabel('True Positive Rate',size=8)\n",
    "# plt.title('Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\",fontsize=8,frameon=False)\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# plt.savefig('roc.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "# Example ROC data\n",
    "fpr = np.linspace(0, 1, 100)\n",
    "tpr = fpr**2 + (np.random.rand(100) - 0.5) * 0.1  # Just an example curve with noise\n",
    "\n",
    "# Smoothed TPR\n",
    "smoothed_tpr = moving_average(tpr, 5)\n",
    "smoothed_fpr = moving_average(fpr, 5)\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"Original ROC\", alpha=0.5)\n",
    "plt.plot(smoothed_fpr, smoothed_tpr, label=\"Smoothed ROC\", color=\"red\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838de0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
