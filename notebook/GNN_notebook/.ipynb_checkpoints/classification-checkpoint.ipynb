{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045a21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, NNConv, global_mean_pool, TopKPooling\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "# from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat, savemat\n",
    "import pandas as pd\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA\n",
    "import copy\n",
    "import math\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "import numpy.linalg as LA\n",
    "import gzip\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# load pickle module\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = 2.5\n",
    "rs = np.array([20, 10, 2.0, 1.0, 0.5, 0.2, 0.1, 0.05, 0.025])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a172fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "WN = np.loadtxt('../W_avg.csv') ### numpy arrary\n",
    "g_m = nx.from_numpy_array(WN)\n",
    "g_m.remove_edges_from(nx.selfloop_edges(g_m))\n",
    "neighbours = list(g_m.neighbors(1858))\n",
    "second_neighbours = []\n",
    "for n in neighbours:\n",
    "    s_n = list(g_m.neighbors(n))\n",
    "    second_neighbours.extend(s_n)\n",
    "second_neighbours = list(set(second_neighbours))\n",
    "all_neighbours = neighbours + second_neighbours\n",
    "position = list(set(all_neighbours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d9a3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph from mobility matrix\n",
    "GM = nx.subgraph(nx.from_numpy_array(WN), position)#nx.from_numpy_array(WN)\n",
    "A_s = nx.adjacency_matrix(GM).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd8c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_s = nx.from_numpy_array(WN)\n",
    "edges = np.array(g_s.edges()).transpose()\n",
    "edge_index = torch.tensor(edges,dtype = torch.int64)\n",
    "# edge_weight = torch.tensor(WN[edge_index[0], edge_index[1]], dtype=torch.float)\n",
    "edge_weights = []\n",
    "for (u, v) in g_s.edges():\n",
    "    edge_weights.append([g_s[u][v]['weight']])\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6007ba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10378"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edge_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc84482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gzipped_numpy(filename):\n",
    "    try:\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            return np.load(f, allow_pickle=True)\n",
    "    except FileNotFoundError:\n",
    "        return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a0087b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 0\n",
      "0.025 1\n"
     ]
    }
   ],
   "source": [
    "export_dir = '/Users/qingyao/Documents/branching_data/simulation/python_cutoff_addno/'\n",
    "#### data preparation\n",
    "dataset = []\n",
    "r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:1}\n",
    "for r_idx in [0,8]:\n",
    "    r = rs[r_idx]\n",
    "    sub_export_dir = export_dir+'branching_R0-{}_r-{}/'.format(np.round(R0,2),np.round(r,3))\n",
    "    r_c = r_class[r]\n",
    "    print(r, r_c)\n",
    "    # Create a list to hold our Data objects\n",
    "    for g_idx in range(300):\n",
    "        export_names = sub_export_dir+'NewInf_R0-{}_r-{}_{}.npy.gz'.format(np.round(R0,2),np.round(r,3),(g_idx+1))\n",
    "        g_i = load_gzipped_numpy(export_names)\n",
    "        matrix = torch.from_numpy(g_i[:,10:])\n",
    "\n",
    "        y = torch.tensor([r_c], dtype=torch.long)\n",
    "        # Create a Data object for each graph\n",
    "        data = Data(x=matrix, edge_index=edge_index, edge_attr=edge_weights,y=y)\n",
    "        data.x = data.x.float()\n",
    "#         data.y = data.y.long()\n",
    "        # Add the Data object to our list\n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41143989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MatrixClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MatrixClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 16)\n",
    "        self.classifier = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the matrix\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dded2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qingyao/anaconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "myloader = DataLoader(dataset.x, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29b6b308",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[38;5;241m.\u001b[39mx\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "dataset.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29080d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Create the model\n",
    "model = MatrixClassifier(data.shape[1] * data.shape[2], num_classes)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(data_tensor)\n",
    "    loss = criterion(outputs, labels_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4d2c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_data, test_data = random_split(dataset, [2160, 540])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3109bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 14.65849, ac: 52.50000\n",
      "Epoch: 001, Loss: 1.21774, ac: 51.16667\n",
      "Epoch: 002, Loss: 0.75519, ac: 58.00000\n",
      "Epoch: 003, Loss: 0.70182, ac: 54.00000\n",
      "Epoch: 004, Loss: 0.69688, ac: 55.50000\n",
      "Epoch: 005, Loss: 0.69217, ac: 58.50000\n",
      "Epoch: 006, Loss: 0.70226, ac: 53.33333\n",
      "Epoch: 007, Loss: 0.69140, ac: 57.66667\n",
      "Epoch: 008, Loss: 0.68848, ac: 57.50000\n",
      "Epoch: 009, Loss: 0.69556, ac: 62.16667\n",
      "Epoch: 010, Loss: 0.68837, ac: 52.83333\n",
      "Epoch: 011, Loss: 0.68484, ac: 67.50000\n",
      "Epoch: 012, Loss: 0.68392, ac: 65.33333\n",
      "Epoch: 013, Loss: 0.68334, ac: 63.50000\n",
      "Epoch: 014, Loss: 0.68813, ac: 64.33333\n",
      "Epoch: 015, Loss: 0.68652, ac: 58.33333\n",
      "Epoch: 016, Loss: 0.68166, ac: 64.66667\n",
      "Epoch: 017, Loss: 0.67772, ac: 67.83333\n",
      "Epoch: 018, Loss: 0.68776, ac: 62.16667\n",
      "Epoch: 019, Loss: 0.67691, ac: 66.16667\n",
      "Epoch: 020, Loss: 0.66057, ac: 78.00000\n",
      "Epoch: 021, Loss: 0.64623, ac: 70.50000\n",
      "Epoch: 022, Loss: 0.64036, ac: 74.33333\n",
      "Epoch: 023, Loss: 0.61492, ac: 73.66667\n",
      "Epoch: 024, Loss: 0.67805, ac: 61.83333\n",
      "Epoch: 025, Loss: 0.70398, ac: 51.83333\n",
      "Epoch: 026, Loss: 0.71462, ac: 50.00000\n",
      "Epoch: 027, Loss: 0.71183, ac: 50.00000\n",
      "Epoch: 028, Loss: 0.70818, ac: 50.00000\n",
      "Epoch: 029, Loss: 0.70372, ac: 50.00000\n",
      "Epoch: 030, Loss: 0.70046, ac: 50.00000\n",
      "Epoch: 031, Loss: 0.69705, ac: 50.00000\n",
      "Epoch: 032, Loss: 0.69551, ac: 50.00000\n",
      "Epoch: 033, Loss: 0.69429, ac: 50.00000\n",
      "Epoch: 034, Loss: 0.68985, ac: 50.00000\n",
      "Epoch: 035, Loss: 0.77092, ac: 50.00000\n",
      "Epoch: 036, Loss: 0.69304, ac: 51.33333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m ac_ep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m     loss,ac,myres, reals \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m     67\u001b[0m     loss_ep\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     68\u001b[0m     ac_ep\u001b[38;5;241m.\u001b[39mappend(ac)\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, label)     \n\u001b[0;32m---> 50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \n\u001b[1;32m     51\u001b[0m loss_all \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_graphs \u001b[38;5;241m*\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module): ### the simpliest model that GNN and it is classical, used as baseline\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 128)        \n",
    "        self.conv2 = GCNConv(128, 64) \n",
    "        self.conv3 = GCNConv(64, 16) \n",
    "        self.classifier = Linear(16, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x) ### \n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Now we can create a DataLoader\n",
    "myloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "# Create a model and an optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(num_node_features=50, num_classes=2).to(device) ### only look at the last 30 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    total = 0\n",
    "    results = []\n",
    "    for data in myloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        output = model(data) \n",
    "        label = data.y.to(device)\n",
    "        y_true.append(label)\n",
    "        loss = F.cross_entropy(output, label)     \n",
    "        loss.backward() \n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step() \n",
    "        \n",
    "        results.append(output)\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)  \n",
    "        total += label.size(0)  \n",
    "        correct += (predicted == label).sum().item()  \n",
    "    accuracy = 100 * correct / total\n",
    "    return loss_all / len(myloader.dataset), accuracy, results, y_true\n",
    "\n",
    "\n",
    "loss_ep = []\n",
    "ac_ep = []\n",
    "for epoch in range(100):\n",
    "    loss,ac,myres, reals = train()\n",
    "    loss_ep.append(loss)\n",
    "    ac_ep.append(ac)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, ac: {:.5f}'.format(epoch, loss, ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6338659e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.12236881e+00, -2.43684220e+00,  4.31513453e+00,\n",
       "         6.79681015e+00],\n",
       "       [-2.19846502e-01,  4.60721672e-01, -1.40032232e-01,\n",
       "        -8.11795712e-01],\n",
       "       [-5.67238235e+00, -1.56570280e+00,  2.56334066e+00,\n",
       "         4.26916742e+00],\n",
       "       [-5.03893471e+00, -1.30753589e+00,  2.25418973e+00,\n",
       "         3.66182637e+00],\n",
       "       [-1.08912909e+00,  8.40183496e-02,  2.88062811e-01,\n",
       "         1.01281285e-01],\n",
       "       [-3.29770637e+00, -8.99070919e-01,  1.36262548e+00,\n",
       "         2.43441534e+00],\n",
       "       [ 1.11834258e-01,  5.62360764e-01, -3.09446663e-01,\n",
       "        -1.09495783e+00],\n",
       "       [-1.56896639e+00,  4.50799428e-02,  5.29239237e-01,\n",
       "         3.16353559e-01],\n",
       "       [ 2.93840021e-01,  6.29411221e-01, -4.12683159e-01,\n",
       "        -1.26436818e+00],\n",
       "       [-8.70569587e-01,  2.74139166e-01,  1.82285011e-01,\n",
       "        -2.70183027e-01],\n",
       "       [ 1.33981943e+00,  1.08440804e+00, -9.06396508e-01,\n",
       "        -2.37075710e+00],\n",
       "       [ 3.56979340e-01,  7.62232721e-01, -4.16002840e-01,\n",
       "        -1.49363196e+00],\n",
       "       [-1.35111296e+00,  4.04915065e-02,  4.07887101e-01,\n",
       "         2.60170847e-01],\n",
       "       [-1.07473707e+00,  1.72134146e-01,  2.91573048e-01,\n",
       "        -5.02356589e-02],\n",
       "       [-3.36163831e+00, -9.12214398e-01,  1.39972734e+00,\n",
       "         2.47751284e+00],\n",
       "       [-1.74828088e+00, -2.24894896e-01,  6.12068415e-01,\n",
       "         8.12356114e-01],\n",
       "       [-7.41395187e+00, -1.97663391e+00,  3.43689632e+00,\n",
       "         5.48460484e+00],\n",
       "       [-6.77890778e-02,  5.33276856e-01, -2.13933617e-01,\n",
       "        -9.98937964e-01],\n",
       "       [-1.17554545e+00,  9.81442779e-02,  3.23440075e-01,\n",
       "         1.13298565e-01],\n",
       "       [-1.59892559e+00, -1.41449347e-01,  5.38864374e-01,\n",
       "         6.33771837e-01],\n",
       "       [-1.46679485e+00, -6.89086691e-02,  4.71704811e-01,\n",
       "         4.62778836e-01],\n",
       "       [-3.11618543e+00, -8.02556455e-01,  1.27922714e+00,\n",
       "         2.22936630e+00],\n",
       "       [-4.10337639e+00, -1.22690070e+00,  1.76202416e+00,\n",
       "         3.23848724e+00],\n",
       "       [-7.87181377e-01,  2.24069580e-01,  1.51147589e-01,\n",
       "        -2.21500814e-01],\n",
       "       [-1.66695046e+00, -1.73534736e-01,  5.69373846e-01,\n",
       "         7.19578743e-01],\n",
       "       [ 3.77983481e-01,  7.14765966e-01, -4.28550929e-01,\n",
       "        -1.43698788e+00],\n",
       "       [-1.34002578e+00,  4.11067046e-02,  4.00727510e-01,\n",
       "         2.54012585e-01],\n",
       "       [-1.58733428e+00, -6.03192896e-02,  5.31931400e-01,\n",
       "         5.17378211e-01],\n",
       "       [-1.57057524e+00, -9.03355479e-02,  5.22670984e-01,\n",
       "         5.46349227e-01],\n",
       "       [-2.19316649e+00, -2.39215568e-01,  8.35007906e-01,\n",
       "         1.00173974e+00],\n",
       "       [-2.14492321e+00, -3.85391355e-01,  8.12290668e-01,\n",
       "         1.21349227e+00],\n",
       "       [-3.82907748e+00, -1.10260642e+00,  1.63734210e+00,\n",
       "         2.96323991e+00],\n",
       "       [-4.96233821e-01,  4.24189389e-01,  1.45487338e-02,\n",
       "        -6.35708809e-01],\n",
       "       [-1.30674267e+00, -5.39193302e-02,  3.96746814e-01,\n",
       "         4.12188411e-01],\n",
       "       [-3.86457038e+00, -1.11105168e+00,  1.65677440e+00,\n",
       "         2.98763847e+00],\n",
       "       [-2.23674107e+00, -2.54855752e-01,  8.71223211e-01,\n",
       "         1.05303049e+00],\n",
       "       [-1.54454696e+00, -4.49743345e-02,  5.04799902e-01,\n",
       "         4.56173658e-01],\n",
       "       [-1.00443542e+00,  1.24290869e-01,  2.42326632e-01,\n",
       "         6.68871403e-03],\n",
       "       [-3.81535679e-01,  4.87242043e-01, -6.44900501e-02,\n",
       "        -7.76203513e-01],\n",
       "       [ 8.06584954e-01,  9.38632250e-01, -6.44472599e-01,\n",
       "        -1.94861031e+00],\n",
       "       [-4.02407026e+00, -1.19906437e+00,  1.72354138e+00,\n",
       "         3.18304348e+00],\n",
       "       [ 2.86416411e-02,  5.44592798e-01, -2.57190824e-01,\n",
       "        -1.05472958e+00],\n",
       "       [-4.81367767e-01,  4.21480477e-01,  7.11441040e-04,\n",
       "        -6.53144240e-01],\n",
       "       [-2.65435934e+00, -5.91201842e-01,  1.06120646e+00,\n",
       "         1.72519314e+00],\n",
       "       [ 4.58944529e-01,  7.64517009e-01, -4.78931338e-01,\n",
       "        -1.53474808e+00],\n",
       "       [-3.47315288e+00, -9.76252556e-01,  1.44893706e+00,\n",
       "         2.62705207e+00],\n",
       "       [-7.86355495e-01,  2.27047622e-01,  1.49774343e-01,\n",
       "        -2.38579214e-01],\n",
       "       [ 7.50056863e-01,  8.40263665e-01, -6.25155449e-01,\n",
       "        -1.76741934e+00],\n",
       "       [-7.50644505e-01,  2.07725540e-01,  1.12390101e-01,\n",
       "        -2.26802647e-01],\n",
       "       [-6.87627196e-01,  2.65473813e-01,  8.53747725e-02,\n",
       "        -3.31294954e-01],\n",
       "       [-4.78068888e-02,  5.78953087e-01, -2.19607770e-01,\n",
       "        -1.03706431e+00],\n",
       "       [-7.85241961e-01,  2.90569663e-01,  1.35281265e-01,\n",
       "        -3.40989828e-01],\n",
       "       [-1.79574907e+00, -2.46799573e-01,  6.25570416e-01,\n",
       "         8.70048940e-01],\n",
       "       [-4.39198196e-01,  3.83009791e-01, -3.87074351e-02,\n",
       "        -6.17954314e-01],\n",
       "       [-1.00632548e+00,  7.26830363e-02,  2.43160307e-01,\n",
       "         9.22369957e-02],\n",
       "       [ 6.06517196e-01,  8.11547756e-01, -5.47668457e-01,\n",
       "        -1.63457894e+00],\n",
       "       [-9.40717101e-01,  1.92582622e-01,  2.06043884e-01,\n",
       "        -1.30534172e-01],\n",
       "       [-8.26244950e-01,  1.93273634e-01,  1.59288764e-01,\n",
       "        -1.61329508e-01],\n",
       "       [-1.48144519e+00, -1.13754608e-02,  4.67931151e-01,\n",
       "         3.88345778e-01],\n",
       "       [-7.00310886e-01,  2.39275306e-01,  9.39961895e-02,\n",
       "        -2.83748925e-01],\n",
       "       [-1.08855164e+00,  7.78888911e-02,  2.84979105e-01,\n",
       "         1.17923886e-01],\n",
       "       [-4.17362124e-01,  4.55817521e-01, -4.22431678e-02,\n",
       "        -7.46101379e-01],\n",
       "       [ 1.16614103e-02,  5.78366876e-01, -2.60984719e-01,\n",
       "        -1.07500100e+00],\n",
       "       [-6.85568571e-01,  2.92181313e-01,  9.86669436e-02,\n",
       "        -3.62368286e-01],\n",
       "       [-3.51765728e+00, -9.84001398e-01,  1.48079979e+00,\n",
       "         2.65399909e+00],\n",
       "       [ 4.69269484e-01,  7.45706081e-01, -4.82932240e-01,\n",
       "        -1.52299631e+00],\n",
       "       [-2.80848432e+00, -4.77260709e-01,  1.14320159e+00,\n",
       "         1.59177732e+00],\n",
       "       [-3.82080674e-03,  5.57280362e-01, -2.42177606e-01,\n",
       "        -1.05668223e+00],\n",
       "       [-4.24945164e+00, -1.28624666e+00,  1.84361184e+00,\n",
       "         3.40152240e+00],\n",
       "       [-2.54576278e+00, -5.08454740e-01,  1.00121891e+00,\n",
       "         1.56910610e+00],\n",
       "       [-1.64943886e+00, -1.89149722e-01,  5.61175346e-01,\n",
       "         7.14943647e-01],\n",
       "       [-1.99586284e+00, -2.71632314e-01,  7.41611481e-01,\n",
       "         9.83816326e-01],\n",
       "       [-4.69918156e+00, -1.25026643e+00,  2.06777072e+00,\n",
       "         3.46766043e+00],\n",
       "       [-3.01807356e+00, -6.45760715e-01,  1.24065518e+00,\n",
       "         1.95315528e+00],\n",
       "       [ 7.88806319e-01,  9.12360013e-01, -6.34680033e-01,\n",
       "        -1.87831521e+00],\n",
       "       [ 5.88421524e-02,  6.09042406e-01, -2.77020961e-01,\n",
       "        -1.13658559e+00],\n",
       "       [-7.19545484e-01,  2.83553839e-01,  1.10375494e-01,\n",
       "        -3.53733838e-01],\n",
       "       [-3.64985704e+00, -1.04445064e+00,  1.54692626e+00,\n",
       "         2.80670881e+00],\n",
       "       [-2.18204427e+00, -3.68616521e-01,  8.23438644e-01,\n",
       "         1.20859897e+00],\n",
       "       [-6.19310975e-01,  3.15578401e-01,  5.29205203e-02,\n",
       "        -4.35980499e-01],\n",
       "       [ 4.78635758e-01,  7.55400896e-01, -4.89040107e-01,\n",
       "        -1.54206681e+00],\n",
       "       [ 8.17302108e-01,  9.14248586e-01, -6.47468328e-01,\n",
       "        -1.88755274e+00],\n",
       "       [-4.56147099e+00, -1.41124904e+00,  1.97854853e+00,\n",
       "         3.69505501e+00],\n",
       "       [-6.72484636e+00, -1.49171484e+00,  3.09632397e+00,\n",
       "         4.47241688e+00],\n",
       "       [-3.16190958e+00, -5.49746394e-01,  1.32913399e+00,\n",
       "         1.79666603e+00],\n",
       "       [-3.08247900e+00, -8.00632775e-01,  1.26867282e+00,\n",
       "         2.21093702e+00],\n",
       "       [-2.48512125e+00, -5.38799047e-01,  9.79003906e-01,\n",
       "         1.58662045e+00],\n",
       "       [-1.06085289e+00,  1.70649722e-01,  2.72732258e-01,\n",
       "        -4.19660807e-02],\n",
       "       [-3.71419597e+00, -1.04427433e+00,  1.57422578e+00,\n",
       "         2.82775116e+00],\n",
       "       [ 2.06350613e+00,  1.39902830e+00, -1.27452910e+00,\n",
       "        -3.09003425e+00],\n",
       "       [-4.00930703e-01,  3.97610188e-01, -5.04050106e-02,\n",
       "        -6.63106799e-01],\n",
       "       [-8.40020657e-01,  1.89249948e-01,  1.71498239e-01,\n",
       "        -1.49056971e-01],\n",
       "       [ 1.26034409e-01,  6.20911121e-01, -3.15901846e-01,\n",
       "        -1.16872692e+00],\n",
       "       [-1.70102847e+00, -2.02018693e-01,  5.83188117e-01,\n",
       "         7.66196012e-01],\n",
       "       [-4.26035976e+00, -1.29519856e+00,  1.84061861e+00,\n",
       "         3.41240835e+00],\n",
       "       [-1.62816250e+00, -4.64221016e-02,  5.45177400e-01,\n",
       "         4.94159043e-01],\n",
       "       [-2.76096582e+00, -6.45032763e-01,  1.09639335e+00,\n",
       "         1.83400178e+00],\n",
       "       [ 2.63224989e-01,  7.02401400e-01, -3.81947011e-01,\n",
       "        -1.35758960e+00],\n",
       "       [-5.04524052e-01,  3.01699460e-01, -1.27897263e-02,\n",
       "        -4.51940298e-01],\n",
       "       [-5.15975773e-01,  4.10034955e-01,  8.15071166e-03,\n",
       "        -6.04638278e-01],\n",
       "       [-3.75626659e+00, -1.08094299e+00,  1.60395420e+00,\n",
       "         2.91106677e+00],\n",
       "       [-3.75152063e+00, -1.08261490e+00,  1.59719741e+00,\n",
       "         2.90602040e+00],\n",
       "       [-1.68818939e+00, -1.32949978e-01,  5.83850086e-01,\n",
       "         6.32849455e-01],\n",
       "       [-2.98274994e+00, -5.37990034e-01,  1.22804379e+00,\n",
       "         1.72441328e+00],\n",
       "       [ 1.04747629e+00,  1.01918769e+00, -7.58223653e-01,\n",
       "        -2.12774706e+00],\n",
       "       [-4.05915785e+00, -1.21213019e+00,  1.74766672e+00,\n",
       "         3.21439171e+00],\n",
       "       [ 4.17894989e-01,  6.91335022e-01, -4.58843440e-01,\n",
       "        -1.41216707e+00],\n",
       "       [-2.53611386e-01,  4.44209039e-01, -1.33509159e-01,\n",
       "        -7.79954553e-01],\n",
       "       [-3.60866642e+00, -1.02634168e+00,  1.51588023e+00,\n",
       "         2.75666595e+00],\n",
       "       [-1.30896306e+00,  2.37522274e-03,  3.97480130e-01,\n",
       "         3.08699638e-01],\n",
       "       [-4.75798893e+00, -1.48689556e+00,  2.06180120e+00,\n",
       "         3.84419918e+00],\n",
       "       [-5.71551919e-01,  3.32331657e-01,  2.31527835e-02,\n",
       "        -4.88575876e-01],\n",
       "       [-6.45370781e-02,  5.21556973e-01, -2.22132832e-01,\n",
       "        -9.59473729e-01],\n",
       "       [-1.60721219e+00, -1.51193857e-01,  5.40985167e-01,\n",
       "         6.61359191e-01],\n",
       "       [-3.88439322e+00, -1.13685358e+00,  1.65996635e+00,\n",
       "         3.03460073e+00],\n",
       "       [-2.76408911e+00, -6.66578710e-01,  1.10545993e+00,\n",
       "         1.89146233e+00],\n",
       "       [-1.73388362e-01,  4.95670140e-01, -1.63384646e-01,\n",
       "        -8.74897957e-01],\n",
       "       [-4.46693122e-01,  3.61589491e-01, -3.69392186e-02,\n",
       "        -5.69204688e-01],\n",
       "       [-1.36010140e-01,  4.81403530e-01, -1.83014363e-01,\n",
       "        -8.82350206e-01],\n",
       "       [-1.60361171e-01,  5.32813728e-01, -1.65435970e-01,\n",
       "        -9.41968679e-01],\n",
       "       [-2.03824377e+00, -3.41205418e-01,  7.54245758e-01,\n",
       "         1.11521673e+00],\n",
       "       [-2.49813771e+00, -5.42219281e-01,  9.62047219e-01,\n",
       "         1.59114039e+00],\n",
       "       [ 6.59932494e-01,  8.43418002e-01, -5.80858469e-01,\n",
       "        -1.72888398e+00],\n",
       "       [-1.88950694e+00, -2.28505298e-01,  6.78025961e-01,\n",
       "         8.62193346e-01],\n",
       "       [-5.60249686e-01,  3.46591949e-01,  3.11092734e-02,\n",
       "        -4.97264981e-01],\n",
       "       [-1.31856441e+00, -1.44229457e-02,  4.05955762e-01,\n",
       "         3.23859483e-01],\n",
       "       [ 3.13156396e-01,  7.39929676e-01, -4.23479646e-01,\n",
       "        -1.45329273e+00],\n",
       "       [ 6.98374510e-02,  6.45587981e-01, -2.88688928e-01,\n",
       "        -1.21137047e+00]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myres[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7002702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 3, 3, 0, 3, 0, 1, 0, 1, 0, 0, 2, 1, 2, 2, 3, 1, 1, 3, 2, 3, 3, 0,\n",
       "        3, 0, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 0, 2, 3, 1, 1, 2, 0, 3, 1, 0,\n",
       "        1, 1, 1, 0, 2, 0, 2, 1, 1, 0, 1, 2, 1, 2, 1, 0, 3, 1, 1, 1, 3, 3, 2, 3,\n",
       "        2, 3, 0, 1, 1, 3, 3, 1, 0, 0, 3, 3, 2, 3, 1, 2, 3, 0, 1, 1, 1, 1, 2, 1,\n",
       "        3, 0, 3, 0, 3, 3, 2, 3, 0, 3, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 0, 0, 2, 1,\n",
       "        1, 3, 0, 2, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f89af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26.5838573 ,  -2.25472993,  16.3684808 ,  14.18632269,\n",
       "         0.96398783,   9.12942606,  -3.34140605,   2.0526191 ,\n",
       "        -3.98905963,  -0.17183989,  -7.84065628,  -4.55066884,\n",
       "         1.63677825,   0.60457326,   9.3197788 ,   3.43631028,\n",
       "        21.35097325,  -2.89140427,   1.08492012,   2.83759491,\n",
       "         2.26283746,   8.44399673,  12.01260936,  -0.13813768,\n",
       "         3.12394919,  -4.45329952,   1.60459948,   2.55567814,\n",
       "         2.5940541 ,   4.43601947,   4.87966681,  11.0617975 ,\n",
       "        -1.45383957,   1.97613953,  11.16541255,   4.64668214,\n",
       "         2.33314645,   0.62901028,  -1.9703486 ,  -6.19614387,\n",
       "        11.79714882,  -3.13397759,  -1.53652936,   6.70679051,\n",
       "        -4.7975899 ,   9.80277777,  -0.18914133,  -5.71230525,\n",
       "        -0.2479022 ,  -0.5576615 ,  -2.9714554 ,  -0.46183729,\n",
       "         3.61448808,  -1.54826802,   0.83571464,  -5.18752599,\n",
       "         0.21306787,   0.02786264,   2.08952418,  -0.42397909,\n",
       "         1.00161876,  -1.86697295,  -3.16860557,  -0.59758966,\n",
       "         9.93959546,  -4.78914732,   6.58447444,  -3.09712154,\n",
       "        12.60554421,   6.2013014 ,   3.07803191,   4.16303962,\n",
       "        13.28825629,   7.69501549,  -5.99194568,  -3.3547563 ,\n",
       "        -0.55689669,  10.46952832,   4.90405768,  -0.88652205,\n",
       "        -4.84887975,  -6.04334629,  13.63101304,  18.11818373,\n",
       "         7.49851966,   8.36952394,   6.17907012,   0.590216  ,\n",
       "        10.58743072, -10.42013264,  -1.69252023,   0.08507551,\n",
       "        -3.51707333,   3.26294558,  12.62326372,   2.52640983,\n",
       "         7.04975927,  -4.13426143,  -1.07970089,  -1.38757846,\n",
       "        10.86016572,  10.82984114,   2.93329856,   7.09133738,\n",
       "        -6.88050079,  11.92637837,  -4.46285307,  -2.16267294,\n",
       "        10.27541661,   1.7234344 ,  14.16930437,  -1.0870904 ,\n",
       "        -2.80112988,   2.91485405,  11.28688133,   7.21872813,\n",
       "        -2.45579302,  -1.41990301,  -2.53167582,  -2.62396425,\n",
       "         4.51293629,   6.15529633,  -5.50495088,   3.71412666,\n",
       "        -1.08298445,   1.76906703,  -4.4669078 ,  -3.56590128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(*np.array([0,1,2,3]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76053a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31dea9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = data.y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a950cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3142, 53], edge_index=[2, 10378], edge_attr=[10378, 1], y=[1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a416dde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.3286, Accuracy: 0.3519\n",
      "Epoch: 2, Loss: 1.2494, Accuracy: 0.4493\n",
      "Epoch: 3, Loss: 1.1736, Accuracy: 0.5074\n",
      "Epoch: 4, Loss: 1.1321, Accuracy: 0.5074\n",
      "Epoch: 5, Loss: 1.0964, Accuracy: 0.5256\n",
      "Epoch: 6, Loss: 1.0727, Accuracy: 0.5304\n",
      "Epoch: 7, Loss: 1.0613, Accuracy: 0.5252\n",
      "Epoch: 8, Loss: 1.0372, Accuracy: 0.5507\n",
      "Epoch: 9, Loss: 1.0209, Accuracy: 0.5389\n",
      "Epoch: 10, Loss: 1.0312, Accuracy: 0.5356\n",
      "Epoch: 11, Loss: 1.0504, Accuracy: 0.5389\n",
      "Epoch: 12, Loss: 1.0339, Accuracy: 0.5356\n",
      "Epoch: 13, Loss: 1.0465, Accuracy: 0.5374\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m---> 60\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m     61\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Learning rate scheduler step\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[0;32mIn[47], line 46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, label)\n\u001b[0;32m---> 46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_graphs\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class ImprovedGCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(ImprovedGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 128)\n",
    "        self.bn1 = BatchNorm(128)\n",
    "        \n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.bn2 = BatchNorm(64)\n",
    "        \n",
    "        self.classifier = torch.nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch, edge_weight = data.x, data.edge_index, data.batch, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Model, optimizer, and scheduler\n",
    "model = ImprovedGCN(num_node_features=50, num_classes=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Train function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in myloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y.to(device)\n",
    "        loss = F.cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        _, predicted = output.max(dim=1)\n",
    "        correct += predicted.eq(label).sum().item()\n",
    "        total += data.num_graphs\n",
    "        \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "accuracies = []\n",
    "for epoch in range(100):\n",
    "    loss, acc = train()\n",
    "    scheduler.step()  # Learning rate scheduler step\n",
    "    \n",
    "    losses.append(loss)\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd1250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
