{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca1d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix, from_networkx\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "import pandas as pd\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA\n",
    "import copy\n",
    "import math\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "import numpy.linalg as LA\n",
    "import gzip\n",
    "from scipy import sparse\n",
    "from torch.utils.data import random_split\n",
    "import time\n",
    "\n",
    "# load pickle module\n",
    "import pickle\n",
    "import networkx as nx\n",
    "# from tqdm import tqdm\n",
    "import sys\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545ee3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../codes/GCN.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f7ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [np.power(0.5, i) for i in range(2, 16, 2)]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f886f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00390625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c3a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_ng(torch.nn.Module):  # the simpliest model that GNN and it is classical, used as baseline\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GCN_ng, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 128)\n",
    "        self.conv2 = GCNConv(128, 64)\n",
    "        self.conv3 = GCNConv(64, 16)\n",
    "        self.conv4 = GCNConv(16, 8)\n",
    "        self.fc = torch.nn.Linear(8, 1)\n",
    "\n",
    "    \"\"\"\n",
    "        hyperparameters:\n",
    "        - number of hidden layers\n",
    "        - number of hidden channels\n",
    "        - dropout rate (now it's zero)\n",
    "        - learning rate <- most important to tune\n",
    "        - weight decay\n",
    "        - etc etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, data):\n",
    "        # x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x, batch = data.x, data.batch\n",
    "        edge_index = torch.Tensor([[], []]).to(x.device).long()\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97ce9a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.080893083602663\n",
      "1 4.0583167182074655\n",
      "2 4.042672326829698\n",
      "3 4.030082913050576\n",
      "4 4.019350860989283\n",
      "5 4.007984139427307\n",
      "6 3.994661515099662\n",
      "7 3.978609083569239\n",
      "8 3.9599446682702926\n",
      "9 3.940372591170054\n",
      "10 3.912268889139569\n",
      "11 3.8796517251029847\n",
      "12 3.8369974295298257\n",
      "13 3.7876985277448383\n",
      "14 3.7263285402267696\n",
      "15 3.6581817929706877\n",
      "16 3.569167208293128\n",
      "17 3.476284569028824\n",
      "18 3.3527408130585203\n",
      "19 3.2428363709222703\n",
      "20 3.0950317148178343\n",
      "21 2.9746818481929718\n",
      "22 2.8076240085420157\n",
      "23 2.6712691435738214\n",
      "24 2.5228989646548317\n",
      "25 2.3777884869348433\n",
      "26 2.2436788944970996\n",
      "27 2.1253075648867896\n",
      "28 2.013202729679289\n",
      "29 1.9428679893887233\n",
      "30 1.8198808231051007\n",
      "31 1.765735440027146\n",
      "32 1.6931871599621242\n",
      "33 1.6526289103523133\n",
      "34 1.63714059534527\n",
      "35 1.588583771387736\n",
      "36 1.5657230059305827\n",
      "37 1.5516878502709526\n",
      "38 1.5160208702087403\n",
      "39 1.5015594149392748\n",
      "40 1.4921401693707421\n",
      "41 1.4853430819889857\n",
      "42 1.467276732505314\n",
      "43 1.5052682373258803\n",
      "44 1.4637004080272855\n",
      "45 1.4358827613648915\n",
      "46 1.4271565032383753\n",
      "47 1.419962687719436\n",
      "48 1.41449427037012\n",
      "49 1.45320512453715\n",
      "50 1.4174427573643034\n",
      "51 1.4002199653595213\n",
      "52 1.4447737099632385\n",
      "53 1.3696032671701341\n",
      "54 1.3624733448028565\n",
      "55 1.3539590744745165\n",
      "56 1.3484626963025048\n",
      "57 1.3477770695610651\n",
      "58 1.3514926997442094\n",
      "59 1.33275815872919\n",
      "60 1.3263689101688445\n",
      "61 1.3177993619252766\n",
      "62 1.3207886794256785\n",
      "63 1.3073366710117884\n",
      "64 1.2966132608671037\n",
      "65 1.2921787769075423\n",
      "66 1.285730308578128\n",
      "67 1.2777556037145947\n",
      "68 1.3047762757255918\n",
      "69 1.2668181339899698\n",
      "70 1.2622197571254912\n",
      "71 1.2632973474169535\n",
      "72 1.2485673821161665\n",
      "73 1.265020887813871\n",
      "74 1.2474809529289366\n",
      "75 1.2346795933587211\n",
      "76 1.2395607225478642\n",
      "77 1.2298278441504826\n",
      "78 1.220934466331724\n",
      "79 1.218819597032335\n",
      "80 1.2126634533443148\n",
      "81 1.222745238410102\n",
      "82 1.2074917751645284\n",
      "83 1.1942273174013411\n",
      "84 1.1934589473028032\n",
      "85 1.2083656977093409\n",
      "86 1.1795120988573347\n",
      "87 1.178204521678743\n",
      "88 1.1743822514064728\n",
      "89 1.1851198275883992\n",
      "90 1.1686142429472908\n",
      "91 1.1606142312761336\n",
      "92 1.1499097392672584\n",
      "93 1.1790480958090888\n",
      "94 1.164586675734747\n",
      "95 1.1432418573470342\n",
      "96 1.1321333752738105\n",
      "97 1.1284401655197143\n",
      "98 1.124439093044826\n",
      "99 1.1157532362710862\n",
      "100 1.114188699873667\n",
      "101 1.110450478205605\n",
      "102 1.1571176634894478\n",
      "103 1.1000002633957635\n",
      "104 1.1043166978018624\n",
      "105 1.1188923610581292\n",
      "106 1.0811164780268594\n",
      "107 1.0961808276554894\n",
      "108 1.0736012405819364\n",
      "109 1.0770479552329533\n",
      "110 1.063026926252577\n",
      "111 1.0663578949277364\n",
      "112 1.0581118649906582\n",
      "113 1.0527162211281913\n",
      "114 1.0461252112237234\n",
      "115 1.0557006665638515\n",
      "116 1.0367424563756065\n",
      "117 1.0334168286550613\n",
      "118 1.0319345481812008\n",
      "119 1.080531222668905\n",
      "120 1.039018105703687\n",
      "121 1.031658985501244\n",
      "122 1.0157019490287418\n",
      "123 1.008800138367547\n",
      "124 1.01064124826401\n",
      "125 1.0344417140597388\n",
      "126 0.9976964615640186\n",
      "127 0.9988790720228164\n",
      "128 0.9857774617179992\n",
      "129 0.9848239266683185\n",
      "130 0.9819634740314787\n",
      "131 0.9776101214545113\n",
      "132 0.9696132232272435\n",
      "133 1.0197078027422466\n",
      "134 0.9586631860051836\n",
      "135 0.9508509395614503\n",
      "136 0.9605624569786919\n",
      "137 0.9464458274462867\n",
      "138 0.9367479638447838\n",
      "139 0.9389214057770986\n",
      "140 0.9272937199426076\n",
      "141 0.934291256230975\n",
      "142 0.9319891923949832\n",
      "143 0.9176654369112045\n",
      "144 0.9147425191743034\n",
      "145 0.9060538963666038\n",
      "146 0.9018255434339009\n",
      "147 0.9098248943449959\n",
      "148 0.8932142851844667\n",
      "149 0.8992042533935063\n",
      "150 0.8857199708620708\n",
      "151 0.8835294015823849\n",
      "152 0.8804145551863171\n",
      "153 0.8942096590995788\n",
      "154 0.885009265324426\n",
      "155 0.9181501335567899\n",
      "156 0.8856563255900428\n",
      "157 0.8657768747163197\n",
      "158 0.8599915561221895\n",
      "159 0.8809657569915529\n",
      "160 0.8604954061054048\n",
      "161 0.8482299040234278\n",
      "162 0.8411633307971652\n",
      "163 0.8603382693396674\n",
      "164 0.8324624756025889\n",
      "165 0.8276174170630318\n",
      "166 0.8414744986428155\n",
      "167 0.8254657069842021\n",
      "168 0.8232124994671534\n",
      "169 0.8149135718269954\n",
      "170 0.8150901542769537\n",
      "171 0.8099079169924297\n",
      "172 0.8026552065970406\n",
      "173 0.7989742027388679\n",
      "174 0.7961228433109465\n",
      "175 0.7923725419574313\n",
      "176 0.7925926263370211\n",
      "177 0.7880734084144471\n",
      "178 0.7965184995106288\n",
      "179 0.782564672212752\n",
      "180 0.7779903428895133\n",
      "181 0.7749967298810444\n",
      "182 0.7756716274079822\n",
      "183 0.7691399296124776\n",
      "184 0.7664003695760454\n",
      "185 0.7675651436760312\n",
      "186 0.7597147194166032\n",
      "187 0.7594401022744557\n",
      "188 0.7545226852099101\n",
      "189 0.7559796889623006\n",
      "190 0.7640440503756205\n",
      "191 0.7458834803293621\n",
      "192 0.7455981023727901\n",
      "193 0.7410313750070239\n",
      "194 0.7394549197620816\n",
      "195 0.7347819841097272\n",
      "196 0.7319967385322329\n",
      "197 0.7390757729136754\n",
      "198 0.767663027559008\n",
      "199 0.7261502721953014\n"
     ]
    }
   ],
   "source": [
    "datafolder = '/Users/qingyao/../../Volumes/Seagate_Qing/branching_data/gnn_regression_1d5/including_large_r/'\n",
    "    # datafolder = '/Users/qingyao/Documents/branching_data/gnn_regression/'\n",
    "\n",
    "num_x = 50\n",
    "layer = 4\n",
    "# save_dir = '/rds/general/user/qy1815/home/branching_superspreading/regression_ng_{}_layer_{}/'.format(\n",
    "#num_x, layer)\n",
    "\n",
    "job_idx = 100 #int(sys.argv[1])-1  # ensemble/parameter index\n",
    "s = job_idx//70\n",
    "es_idx = 4 # job_idx % 70  # ensemble/parameter index\n",
    "s = 1 #int(s)  # seed index\n",
    "\n",
    "    # load data\n",
    "    # WN = np.loadtxt('W_avg.csv')\n",
    "dataset = torch.load(datafolder+'dataset_{}.pt'.format(num_x))\n",
    "lr_list = [np.power(0.5, i) for i in range(2, 16, 2)]*10\n",
    "my_lr = 0.0001 #lr_list[es_idx]\n",
    "\n",
    "torch.manual_seed(s)\n",
    "all_data_len = len(dataset)\n",
    "train_size = int(all_data_len * 0.6)\n",
    "val_size = int(all_data_len * 0.2)\n",
    "test_size = all_data_len - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(\n",
    "        dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    # Now we can create a DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=128, shuffle=True)\n",
    "    # Create a model and an optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = GCN_ng(num_node_features=num_x, hidden_channels=[\n",
    "#         128, 64, 16, 8], num_hlayers=layer).to(device)\n",
    "\n",
    "model = GCN_ng(num_node_features=num_x).to(device)\n",
    "# model = MLP(num_node_features=num_x, hidden_channels=[\n",
    "#         128, 64, 16, 8], num_hlayers=layer).to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=my_lr, weight_decay=5e-4)\n",
    "\n",
    "    # training and validation\n",
    "counter = 0\n",
    "count_epochs = 0\n",
    "best = float(\"inf\")\n",
    "epochs = 200\n",
    "patience = 15\n",
    "loss_ep = []\n",
    "\n",
    "seed = int(time.time()) + es_idx\n",
    "# random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, myres, reals = train(model, train_loader, optimizer, device)\n",
    "    # loss_ep.append(loss)\n",
    "    val_loss = validate(model, val_loader, device)\n",
    "    loss_ep.append(val_loss)\n",
    "    print(epoch, val_loss)\n",
    "    if val_loss < best:\n",
    "        best = val_loss\n",
    "        counter = 0\n",
    "        # Save the best model\n",
    "#         torch.save(model.state_dict(\n",
    "#         ), save_dir+'best_model_{}_{}.pth'.format(s, es_idx))\n",
    "    else:\n",
    "        counter += 1\n",
    "        count_epochs += 1\n",
    "\n",
    "    if counter > patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076c9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
