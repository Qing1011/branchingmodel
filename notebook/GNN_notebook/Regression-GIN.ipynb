{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045a21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, NNConv, global_mean_pool, TopKPooling\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.data import Data,DataLoader\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat, savemat\n",
    "import pandas as pd\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA\n",
    "import copy\n",
    "import math\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "import numpy.linalg as LA\n",
    "import gzip\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "# load pickle module\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = 2.5\n",
    "rs = np.array([20, 10, 2.0, 1.0, 0.5, 0.2, 0.1, 0.05, 0.025, 5.   ,  2.5  , 13.333,  3.333,  1.333,  0.667,  0.286,  0.133,\n",
    "        0.067,  0.033])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed78b4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.99573227,  2.30258509,  0.69314718,  0.        , -0.69314718,\n",
       "       -1.60943791, -2.30258509, -2.99573227, -3.68887945,  1.60943791,\n",
       "        0.91629073,  2.59024217,  1.2038728 ,  0.28743204, -0.40496523,\n",
       "       -1.25176347, -2.01740615, -2.70306266, -3.41124772])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.sort()\n",
    "np.log(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f87e89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56b6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "WN = np.loadtxt('../W_avg.csv') ### numpy arrary\n",
    "WN2 = np.dot(WN, WN)\n",
    "# prob = WN[:,1858]\n",
    "prob = WN2[:,1858]\n",
    "prob_2d = prob.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c46fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fbbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_s = nx.from_numpy_array(WN)\n",
    "edges = np.array(g_s.edges()).transpose()\n",
    "edge_index = torch.tensor(edges,dtype = torch.int64)\n",
    "# edge_weight = torch.tensor(WN[edge_index[0], edge_index[1]], dtype=torch.float)\n",
    "edge_weights = []\n",
    "for (u, v) in g_s.edges():\n",
    "#     weight = prob[v]\n",
    "    edge_weights.append([g_s[u][v]['weight']])\n",
    "edge_weights = torch.tensor(edge_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc84482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gzipped_numpy(filename):\n",
    "    try:\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            return np.load(f, allow_pickle=True)\n",
    "    except FileNotFoundError:\n",
    "        return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0087b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025 3\n",
      "0.033 3\n",
      "0.05 3\n",
      "0.067 3\n",
      "0.1 2\n",
      "0.133 2\n",
      "0.2 2\n",
      "0.286 2\n",
      "0.5 1\n",
      "0.667 1\n",
      "1.0 1\n",
      "1.333 1\n",
      "2.0 1\n",
      "2.5 1\n",
      "3.333 1\n",
      "5.0 0\n",
      "10.0 0\n",
      "13.333 0\n",
      "20.0 0\n"
     ]
    }
   ],
   "source": [
    "export_dir = '/Users/qingyao/Documents/branching_data/simulation/python_cutoff_addno/'\n",
    "#### data preparation\n",
    "dataset = []\n",
    "r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3, \n",
    "           5.0:0 ,  2.5:1  , 13.333:0,  3.333:1,  1.333:1,  0.667:1,  0.286:2,  0.133:2,\n",
    "        0.067:3,  0.033:3}\n",
    "for r_idx in range(19):\n",
    "    r = rs[r_idx]\n",
    "    sub_export_dir = export_dir+'branching_R0-{}_r-{}/'.format(np.round(R0,2),np.round(r,3))\n",
    "    r_c = r_class[r]\n",
    "    print(r, r_c)\n",
    "    # Create a list to hold our Data objects\n",
    "    for g_idx in range(300):\n",
    "        export_names = sub_export_dir+'NewInf_R0-{}_r-{}_{}.npy.gz'.format(np.round(R0,2),np.round(r,3),(g_idx+1))\n",
    "        g_i = load_gzipped_numpy(export_names)\n",
    "#         g_i_new = np.hstack((g_i[:,10:], prob_2d))\n",
    "#         g_i_new = g_i[:,10:] * prob_2d\n",
    "        g_i_new = g_i[:,10:]\n",
    "        \n",
    "        matrix = torch.from_numpy(g_i_new)\n",
    "        \n",
    "        y = torch.log(torch.tensor([[r]], dtype=torch.float))\n",
    "#         y = torch.tensor([[r]], dtype=torch.float)\n",
    "        # Create a Data object for each graph\n",
    "        data = Data(x=matrix, edge_index=edge_index, edge_attr=edge_weights,y=y)\n",
    "        data.x = data.x.float()\n",
    "#         data.y = data.y.long()\n",
    "        # Add the Data object to our list\n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3079dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "all_data_len = len(dataset)\n",
    "train_data, test_data = random_split(dataset, [int(all_data_len*0.8), int(all_data_len*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41143989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Sequential_62aded.forward() missing 1 required positional argument: 'edge_attr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m loss_ep\u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))):\n\u001b[0;32m---> 86\u001b[0m     loss, myres, reals \u001b[38;5;241m=\u001b[39m train(model, optimizer, myloader)\n\u001b[1;32m     87\u001b[0m     loss_ep\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m#     ac_ep.append(ac)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader)\u001b[0m\n\u001b[1;32m     56\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[0;32m---> 58\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data) \n\u001b[1;32m     59\u001b[0m label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m y_true\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m, in \u001b[0;36mGIN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     30\u001b[0m     x, edge_index, edge_weight, batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39medge_attr, data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index, edge_weight))\n\u001b[1;32m     33\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_weight))\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m global_mean_pool(x, batch)  \u001b[38;5;66;03m# Global pooling over all nodes in each graph\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/nn_conv.py:102\u001b[0m, in \u001b[0;36mNNConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m     99\u001b[0m     x: OptPairTensor \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_attr\u001b[38;5;241m=\u001b[39medge_attr, size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    104\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight:\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 467\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    469\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/nn_conv.py:114\u001b[0m, in \u001b[0;36mNNConv.message\u001b[0;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, edge_attr: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn(edge_attr)\n\u001b[1;32m    115\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels_l, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmatmul(x_j\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), weight)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: Sequential_62aded.forward() missing 1 required positional argument: 'edge_attr'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import NNConv, global_mean_pool, Sequential\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        # Define MLP for GINConv\n",
    "        nn1 = Sequential('x, edge_attr', [\n",
    "            (torch.nn.Linear(1, 25), 'x, edge_attr -> x'),\n",
    "            (torch.nn.ReLU(), 'x -> x'),\n",
    "            (torch.nn.Linear(25, num_node_features * 64), 'x -> x')\n",
    "        ])\n",
    "\n",
    "        nn2 = Sequential('x, edge_attr', [\n",
    "            (torch.nn.Linear(1, 20), 'x, edge_attr -> x'),  # input is edge attribute size, output is hidden dimension\n",
    "            (torch.nn.ReLU(), 'x -> x'),\n",
    "            (torch.nn.Linear(20, 64 * 8), 'x -> x')  # transforming to the size required for the next layer\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.conv1 = NNConv(num_node_features, 64, nn1, aggr='mean')\n",
    "        self.conv2 = NNConv(64, 8, nn2, aggr='mean')\n",
    "#         self.conv3 = NNConv(nn3)\n",
    "#         self.conv4 = NNConv(nn4)\n",
    "        self.fc = torch.nn.Linear(8, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_weight))\n",
    "        x = F.elu(self.conv2(x, edge_index, edge_weight))\n",
    "\n",
    "        x = global_mean_pool(x, batch)  # Global pooling over all nodes in each graph\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Now we can create a DataLoader\n",
    "myloader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "# Create a model and an optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GIN(num_node_features=50).to(device) ### only look at the last 30 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "def train(model, optimizer, loader):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    correct = 0\n",
    "    y_true = []\n",
    "    total = 0\n",
    "    results = []\n",
    "    for data in myloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        output = model(data) \n",
    "        label = data.y.to(device)\n",
    "        y_true.append(label)\n",
    "        \n",
    "        # Calculate weights based on extremes\n",
    "#         weights = calculate_weights(label, -2.8,2)\n",
    "        # Use the custom weighted loss function\n",
    "#         loss = weighted_mse_loss(output, label, weights)\n",
    "        loss = F.mse_loss(output, label) \n",
    "#         loss = F.cross_entropy(output, label)\n",
    "        loss.backward() \n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        \n",
    "        optimizer.step() \n",
    "        results.append(output)\n",
    "    \n",
    "    return loss_all / len(myloader.dataset), results, y_true\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "count_epochs = 0\n",
    "best = float(\"inf\")\n",
    "epochs = 100\n",
    "patience = 15\n",
    "loss_ep= []\n",
    " \n",
    "for epoch in (pbar := tqdm(range(1, epochs + 1))):\n",
    "    loss, myres, reals = train(model, optimizer, myloader)\n",
    "    loss_ep.append(loss)\n",
    "#     ac_ep.append(ac)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, loss))\n",
    "    if loss < best:\n",
    "        best = loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        count_epochs += 1\n",
    "        \n",
    "    if counter > patience:\n",
    "        break\n",
    "        # print(f\"Epoch: {​​​​​​epoch:03d}​​​​​​, Loss: {​​​​​​loss:.4f}​​​​​​\")\n",
    "#     scheduler.step()\n",
    "    pbar.set_description(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}\")\n",
    "print(\"\\n\", \"Stopped early at epoch: \", count_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f825ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the edge index to see if the graph is helping\n",
    "## remove the conv layers, relu--> linear regression works\n",
    "## r values which have never see before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf993a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "def bootstrap_median_confidence_interval(data, ci=95, n_bootstraps=10000):\n",
    "    bootstrapped_medians = []\n",
    "    n = len(data)\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        bootstrapped_medians.append(np.median(sample))\n",
    "\n",
    "    lower_bound = np.percentile(bootstrapped_medians, (100 - ci) / 2)\n",
    "    upper_bound = np.percentile(bootstrapped_medians, 100 - (100 - ci) / 2)\n",
    "    medians = np.percentile(bootstrapped_medians, 50)\n",
    "\n",
    "    return medians, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - (100 - ci) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9233f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y = []\n",
    "training_true = []\n",
    "for t_s in range(17):\n",
    "    training_y.extend(list(myres[t_s].detach().ravel().numpy()))\n",
    "    training_true.extend(list(reals[t_s].detach().ravel().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2fde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = {}\n",
    "for p, t in zip(training_y, training_true):\n",
    "    real_r = np.round(np.exp(t),3)\n",
    "    if real_r in training.keys():\n",
    "        training[real_r].append(p)\n",
    "    else:\n",
    "        training[real_r] = [p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ab083",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrap_ci = []\n",
    "Bootstrap_mean = []\n",
    "for r_idx in range(19):\n",
    "    r = rs[r_idx]\n",
    "    r = np.float32(r)\n",
    "    print(r)\n",
    "    data = np.exp(training[r])\n",
    "#     data = training[r]\n",
    "#     k = np.log(r)\n",
    "#     print(len(data))\n",
    "#     Bootstrap_mean.append(np.median(data))\n",
    "    sample_median, l_b, u_b = bootstrap_median_confidence_interval(data,95)\n",
    "    Bootstrap_ci.append([l_b, u_b])\n",
    "    Bootstrap_mean.append(sample_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37181b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = np.array(Bootstrap_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf865f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rs,rs,label='real')\n",
    "plt.scatter(rs,np.array(Bootstrap_mean),label='trained')\n",
    "plt.fill_between(rs,CI[:,1],CI[:,0],alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "# plt.savefig('regression.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a9f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    total_loss = 0\n",
    "    true_values = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            loss = F.mse_loss(output, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            predictions.append(output.cpu())\n",
    "            true_values.append(data.y.cpu())\n",
    "    return torch.cat(predictions, dim=0), torch.cat(true_values, dim=0),total_loss / len(testloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd1250",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true, test_mse  = test()\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for p, t in zip(predictions.ravel().numpy(), y_true.ravel().numpy()):\n",
    "    real_r = np.round(np.exp(t),3)\n",
    "    if real_r in results.keys():\n",
    "        results[real_r].append(p)\n",
    "    else:\n",
    "        results[real_r] = [p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edc9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'results' is your dictionary\n",
    "with open('gnn_regression.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_idx in range(9):\n",
    "    r = rs[r_idx]\n",
    "    r = np.float32(r)\n",
    "    data = results[r]\n",
    "    k = np.log(r)\n",
    "    print(k)\n",
    "    print(\"T-Distribution 99% Confidence Interval:\", t_distribution_confidence_interval(data,99))\n",
    "#     print(\"Bootstrap 95% Confidence Interval:\", bootstrap_confidence_interval(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7800e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34387992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrap_ci = []\n",
    "Bootstrap_mean = []\n",
    "per_95 = []\n",
    "per_5 = []\n",
    "for r_idx in range(19):\n",
    "    r = rs[r_idx]\n",
    "    r = np.float32(r)\n",
    "    print(r)\n",
    "    data = np.exp(results[r])\n",
    "#     data = training[r]\n",
    "#     k = np.log(r)\n",
    "#     print(len(data))\n",
    "#     Bootstrap_mean.append(np.median(data))\n",
    "    sample_median, l_b, u_b = bootstrap_median_confidence_interval(data,95,n_bootstraps=100)\n",
    "    Bootstrap_ci.append([l_b, u_b])\n",
    "    Bootstrap_mean.append(sample_median)\n",
    "    per_95.append(np.percentile(data,95))\n",
    "    per_5.append(np.percentile(data,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0bde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = np.array(Bootstrap_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rs,rs,label='real',c='grey')\n",
    "plt.scatter(rs,np.array(Bootstrap_mean),label='test')\n",
    "plt.fill_between(rs,CI[:,1],CI[:,0],alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9053dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = rs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c026c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,2.),dpi=450)\n",
    "colors = {0:'orange',1:'yellowgreen',2:'lightskyblue',3:'cornflowerblue'}\n",
    "# r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3}\n",
    "r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3, \n",
    "           5.0:0 ,  2.5:1  , 13.333:0,  3.333:1,  1.333:1,  0.667:1,  0.286:2,  0.133:2,\n",
    "        0.067:3,  0.033:3}\n",
    "line_properties = dict(linestyle='-', linewidth=0.75, color='gray')\n",
    "\n",
    "\n",
    "for r_idx in range(19):\n",
    "    r = rs[r_idx]\n",
    "    k = np.log(r)\n",
    "    c = r_class[r]\n",
    "    r = np.float32(r)\n",
    "    # Plot each boxplot at position k_idx + 1\n",
    "#     y = np.exp()\n",
    "#     ax.boxplot(results[k], positions=[k_idx + 1])\n",
    "    real_pr = np.exp(results[r])\n",
    "    std = np.std(real_pr)\n",
    "    \n",
    "    ax.boxplot(real_pr, positions=[r_idx+1],showfliers=False,\n",
    "               boxprops = dict(linestyle='-', linewidth=0.75, color='gray'),\n",
    "               whiskerprops=line_properties, widths=0.6,\n",
    "           capprops=line_properties,\n",
    "              medianprops=dict(linestyle='-', linewidth=0.75, color='gray'))\n",
    "    \n",
    "    myc = colors[c]\n",
    "    # Plot the scatter point at the same position\n",
    "    ax.scatter(r_idx + 1, r, color=myc, s=5)\n",
    "\n",
    "    print(len(results[r]))\n",
    "\n",
    "# Show the plot after adding all boxplots\n",
    "ax.set_xticks(np.array([0,2,4,6,8,10,12,14,16,18])+1)  # Setting x-ticks positions\n",
    "ax.set_xticklabels(rs[[0,2,4,6,8,10,12,14,16,18]])  # Assuming 'rs' is your array of labels\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.ylim(-5,4)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('$r$',size=8)\n",
    "plt.ylabel('$r$',size=8)\n",
    "ax.tick_params(axis='both', labelsize=8)\n",
    "# plt.show()\n",
    "# plt.savefig(\"gnn_regression.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b06357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'results' and 'rs' are defined as before\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.5,2), dpi=450)\n",
    "\n",
    "colors = {0:'orange', 1:'yellowgreen', 2:'lightskyblue', 3:'cornflowerblue'}\n",
    "# r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3}\n",
    "\n",
    "for r_idx in range(19):\n",
    "    r = rs[r_idx]\n",
    "    k = np.log(r)\n",
    "    c = r_class[r]\n",
    "    r = np.float32(r)\n",
    "    \n",
    "    # Creating the violin plot at position r_idx + 1\n",
    "    vp = ax.violinplot(results[r], positions=[r_idx + 1], showmeans=False, showmedians=False, showextrema=False)\n",
    "    \n",
    "    # You can set the color of each part of the violin plot\n",
    "    for pc in vp['bodies']:\n",
    "        pc.set_facecolor('grey')\n",
    "        pc.set_edgecolor('grey')\n",
    "        pc.set_alpha(0.5)\n",
    "\n",
    "    # Plot the scatter point at the same position\n",
    "    ax.scatter(r_idx + 1, k, color=colors[c], s=5)\n",
    "\n",
    "# Setting x-ticks positions and labels\n",
    "ax.set_xticks(range(1, 20))\n",
    "ax.set_xticklabels(rs)\n",
    "\n",
    "# Setting the limits for y-axis and font size for ticks\n",
    "plt.ylim(-5, 4)\n",
    "plt.xlabel('$r$')\n",
    "plt.ylabel('$\\log(r)$')\n",
    "ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeaee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = rs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5,2),dpi=450)\n",
    "colors = {0:'orange',1:'yellowgreen',2:'lightskyblue',3:'cornflowerblue'}\n",
    "# r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3}\n",
    "r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3, \n",
    "           5.0:0 ,  2.5:1  , 13.333:0,  3.333:1,  1.333:1,  0.667:1,  0.286:2,  0.133:2,\n",
    "        0.067:3,  0.033:3}\n",
    "line_properties = dict(linestyle='-', linewidth=0.75, color='gray')\n",
    "\n",
    "# plt.plot(rs,rs,label='real',c='grey')\n",
    "plt.plot(rs,np.array(Bootstrap_mean),ls='--',lw=0.7,color='white')\n",
    "\n",
    "plt.fill_between(rs, np.array(per_5),np.array(per_95),\n",
    "                 alpha=0.1,color='blue')\n",
    "plt.fill_between(rs,CI[:,1],CI[:,0],alpha=0.5,color='grey')\n",
    "\n",
    "for r_idx in range(19):\n",
    "    r = rs[r_idx]\n",
    "    k = np.log(r)\n",
    "    c = r_class[r]\n",
    "    r = np.float32(r)\n",
    "    # Plot each boxplot at position k_idx + 1\n",
    "#     y = np.exp()\n",
    "#     ax.boxplot(results[k], positions=[k_idx + 1])\n",
    "#     real_pr = np.exp(results[r])\n",
    "#     std_list.append(np.std(real_pr))\n",
    "#     median_list.append(np.median(real_pr))\n",
    "\n",
    "    \n",
    "#     ax.boxplot(real_pr, positions=[r_idx+1],showfliers=False,\n",
    "#                boxprops = dict(linestyle='-', linewidth=0.75, color='gray'),\n",
    "#                whiskerprops=line_properties, widths=0.4,\n",
    "#            capprops=line_properties,\n",
    "#               medianprops=dict(linestyle='-', linewidth=1, color='gray'))\n",
    "    \n",
    "    myc = colors[c]\n",
    "    # Plot the scatter point at the same position\n",
    "    ax.scatter(r, r, color=myc, s=5)\n",
    "\n",
    "#     print(len(results[r]))\n",
    "# plt.plot(rs, median_list,ls='--',lw=0.7)\n",
    "\n",
    "# Show the plot after adding all boxplots\n",
    "# label_pos = np.array([0,2,4,6,8,10,12,15,16,18])+1\n",
    "# ax.set_xticks(label_pos)  # Setting x-ticks positions\n",
    "# ax.set_xticklabels(rs[[0,2,4,6,8,10,12,15,16,18]])  # Assuming 'rs' is your array of labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "# plt.ylim(-5,4)\n",
    "plt.xlabel('$r$',size=8)\n",
    "plt.ylabel('$r$',size=8)\n",
    "ax.tick_params(axis='both', labelsize=8)\n",
    "# plt.show()\n",
    "# plt.savefig(\"gnn_regression.pdf\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_add = np.array([12.5 ,  4.  ,  0.4 ,  0.08])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = '/Users/qingyao/Documents/branching_data/simulation/unseen/'\n",
    "#### data preparation\n",
    "dataset = []\n",
    "r_class = {12.5:0 ,  4.:1  ,  0.4:2 ,  0.08:3}\n",
    "for r_idx in range(4):\n",
    "    r = rs_add[r_idx]\n",
    "    sub_export_dir = export_dir+'branching_R0-{}_r-{}/'.format(np.round(R0,2),np.round(r,3))\n",
    "    r_c = r_class[r]\n",
    "    print(r, r_c)\n",
    "    # Create a list to hold our Data objects\n",
    "    for g_idx in range(300):\n",
    "        export_names = sub_export_dir+'NewInf_R0-{}_r-{}_{}.npy.gz'.format(np.round(R0,2),np.round(r,3),(g_idx+1))\n",
    "        g_i = load_gzipped_numpy(export_names)\n",
    "#         g_i_new = np.hstack((g_i[:,10:], prob_2d))\n",
    "        g_i_new = g_i[:,10:] * prob_2d\n",
    "        \n",
    "        matrix = torch.from_numpy(g_i_new)\n",
    "        \n",
    "        y = torch.log(torch.tensor([[r]], dtype=torch.float))\n",
    "#         y = torch.tensor([[r]], dtype=torch.float)\n",
    "        # Create a Data object for each graph\n",
    "        data = Data(x=matrix, edge_index=edge_index, edge_attr=edge_weights,y=y)\n",
    "        data.x = data.x.float()\n",
    "#         data.y = data.y.long()\n",
    "        # Add the Data object to our list\n",
    "        dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b208d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y_true, test_mse  = test()\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for p, t in zip(predictions.ravel().numpy(), y_true.ravel().numpy()):\n",
    "    real_r = np.round(np.exp(t),3)\n",
    "    if real_r in results.keys():\n",
    "        results[real_r].append(p)\n",
    "    else:\n",
    "        results[real_r] = [p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bootstrap_ci = []\n",
    "Bootstrap_mean = []\n",
    "per_95 = []\n",
    "per_5 = []\n",
    "for r_idx in range(4):\n",
    "    r = rs_add[r_idx]\n",
    "    r = np.float32(r)\n",
    "    print(r)\n",
    "    data = np.exp(results[r])\n",
    "#     data = training[r]\n",
    "#     k = np.log(r)\n",
    "#     print(len(data))\n",
    "#     Bootstrap_mean.append(np.median(data))\n",
    "    sample_median, l_b, u_b = bootstrap_median_confidence_interval(data,95,n_bootstraps=100)\n",
    "    Bootstrap_ci.append([l_b, u_b])\n",
    "    Bootstrap_mean.append(sample_median)\n",
    "    per_95.append(np.percentile(data,95))\n",
    "    per_5.append(np.percentile(data,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ef00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = np.array(Bootstrap_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597b9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rs_add,rs_add,label='real',c='grey')\n",
    "plt.scatter(rs_add,np.array(Bootstrap_mean),label='test')\n",
    "plt.fill_between(rs_add,CI[:,1],CI[:,0],alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c9fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,2.),dpi=450)\n",
    "colors = {0:'orange',1:'yellowgreen',2:'lightskyblue',3:'cornflowerblue'}\n",
    "# r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3}\n",
    "# r_class = {20:0, 10:0, 2.0:1, 1.0:1, 0.5:1, 0.2:2, 0.1:2, 0.05:3, 0.025:3, \n",
    "#            5.0:0 ,  2.5:1  , 13.333:0,  3.333:1,  1.333:1,  0.667:1,  0.286:2,  0.133:2,\n",
    "#         0.067:3,  0.033:3}\n",
    "line_properties = dict(linestyle='-', linewidth=0.75, color='gray')\n",
    "\n",
    "\n",
    "for r_idx in range(4):\n",
    "    r = rs_add[r_idx]\n",
    "    k = np.log(r)\n",
    "    c = r_class[r]\n",
    "    r = np.float32(r)\n",
    "    # Plot each boxplot at position k_idx + 1\n",
    "#     y = np.exp()\n",
    "#     ax.boxplot(results[k], positions=[k_idx + 1])\n",
    "    real_pr = np.exp(results[r])\n",
    "    std = np.std(real_pr)\n",
    "    \n",
    "    ax.boxplot(real_pr, positions=[r_idx+1],showfliers=False,\n",
    "               boxprops = dict(linestyle='-', linewidth=0.75, color='gray'),\n",
    "               whiskerprops=line_properties, widths=0.6,\n",
    "           capprops=line_properties,\n",
    "              medianprops=dict(linestyle='-', linewidth=0.75, color='gray'))\n",
    "    \n",
    "    myc = colors[c]\n",
    "    # Plot the scatter point at the same position\n",
    "    ax.scatter(r_idx + 1, r, color=myc, s=5)\n",
    "\n",
    "    print(len(results[r]))\n",
    "\n",
    "# Show the plot after adding all boxplots\n",
    "ax.set_xticks(np.array([0,1,2,3])+1)  # Setting x-ticks positions\n",
    "ax.set_xticklabels(rs_add)  # Assuming 'rs' is your array of labels\n",
    "plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "# plt.ylim(-5,4)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('$r$',size=8)\n",
    "plt.ylabel('$r$',size=8)\n",
    "ax.tick_params(axis='both', labelsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7b900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
