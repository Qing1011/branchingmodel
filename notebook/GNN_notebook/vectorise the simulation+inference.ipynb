{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c15771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f0967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WN = np.loadtxt('W_avg.csv')\n",
    "pop = np.loadtxt('pop_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "80650951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpidemicSimulator(MessagePassing):\n",
    "    def __init__(self, r, p, weight, max_time_step):\n",
    "        super(EpidemicSimulator, self).__init__(aggr='add')\n",
    "        self.r = r\n",
    "#         self.p = p\n",
    "        self.p_prime = 1-p\n",
    "        self.max_time_step = max_time_step\n",
    "        self.Z = 3 # latent period\n",
    "        self.Zb = 1 # scale parameter for Z\n",
    "        self.D = 5 # infectious period\n",
    "        self.Db = 1 # scale parameter for beta\n",
    "        self.weight = torch.Tensor(weight)\n",
    "#         print(self.weight)\n",
    "        self.offspring = []\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, step):\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_attr=edge_attr, step=step)\n",
    "\n",
    "    def message(self, x_j, edge_index, edge_attr, step):\n",
    "        # x_j has shape [E, num_features]\n",
    "        # edge_attr has shape [E, num_edge_features]\n",
    "        # Get the new infections from x_j.\n",
    "        new_infectors = x_j[:, 2+step:3+step] ## the infectors at time ti\n",
    "        temp = new_infectors.round().int()\n",
    "        cases = temp.squeeze().tolist()\n",
    "        # Initialize an empty tensor to store the results\n",
    "        results = torch.zeros_like(new_infectors)\n",
    "        # Generate negative binomial for each size\n",
    "        for i, size in enumerate(cases):\n",
    "#             print(size)\n",
    "            if size>0:\n",
    "                offspring_per_case = torch.distributions.Categorical(self.weight).sample(sample_shape=torch.Size([size]))\n",
    "            #torch.distributions.negative_binomial.NegativeBinomial(self.r,self.p_prime).sample(sample_shape=torch.Size([size]))\n",
    "                self.offspring.extend(offspring_per_case.tolist())\n",
    "                temp_sum = offspring_per_case.sum()\n",
    "            else:\n",
    "                temp_sum = 0\n",
    "#             print(temp_sum)\n",
    "            results[i] = temp_sum\n",
    "        ######^^^^^^#######\n",
    "        # Compute the messages.\n",
    "        messages = results * edge_attr.view(-1, 1)\n",
    "        return messages\n",
    "\n",
    "    def update(self, aggr_out, x, step):\n",
    "        # x has shape [N, num_features], it is the original node features\n",
    "        # The new infections are the aggregated messages.\n",
    "        new_infections = aggr_out # aggr_out has shape [N, 1], it contains the updated infections\n",
    "        #### Add the effective infections to the column corresponding to the current step.####\n",
    "        ## immu first\n",
    "        population = x[:, 1:2]\n",
    "        total_infection = torch.sum(x[:, 2:3+step], dim=1,keepdim=True) \n",
    "        rate = (population - total_infection) / population # Compute the rate.\n",
    "        rate[rate<0] = 0\n",
    "        \n",
    "        new_effective_infections = new_infections*rate\n",
    "        new_infections_int  = new_effective_infections.round().int()\n",
    "        ### diffuse the new_infections to different times \n",
    "        inf_sizes = new_infections_int.squeeze().tolist()\n",
    "        for i, inf_size_i in enumerate(inf_sizes):\n",
    "            gamma_dist1 = torch.distributions.Gamma(self.Z, 1/self.Zb)\n",
    "            gamma_dist2 = torch.distributions.Gamma(self.D, 1/self.Db)\n",
    "            latency_p = gamma_dist1.rsample(sample_shape=torch.Size([inf_size_i]))\n",
    "            infectious_p = gamma_dist2.rsample(sample_shape=torch.Size([inf_size_i]))\n",
    "            v = torch.rand(inf_size_i)\n",
    "            delay_days = latency_p + v * infectious_p\n",
    "#             print(step, delay_days)\n",
    "            for j,delay_t in enumerate(delay_days):\n",
    "                t_j = (3+step+delay_t).ceil().int()\n",
    "                if t_j > self.max_time_step:\n",
    "                    pass\n",
    "                else:\n",
    "                    x[i,t_j] = x[i,t_j] + 1\n",
    "        ######^^^^^^#######\n",
    "        # The rest of the features remain the same.\n",
    "        other_features = x[:, 2:].clone()\n",
    "        # Concatenate the new infections, the population, and the other features to get the new node features.\n",
    "        x_new = torch.cat([new_infections.clone(), population, other_features], dim=1)\n",
    "        return x_new, self.offspring\n",
    "\n",
    "def simulate_dynamics(data, R0, r, num_steps):\n",
    "    p = r/(R0+r)  \n",
    "    xx = np.arange(0,100,1)  # define the range of x values the cutoff is 200\n",
    "#     pmf = SSA.nbinom.pmf(xx, r, p)  # calculate the probability mass function\n",
    "    pmf = SSA.nbinom.pmf(xx, r.detach().numpy(), p.detach().numpy())\n",
    "    weights_n = pmf/np.sum(pmf)\n",
    "#     print(weights_n)\n",
    "    x = data.x\n",
    "    T_len = data.x.shape[1]\n",
    "    simulator = EpidemicSimulator(r,p, weights_n, max_time_step=(T_len-1))\n",
    "    for ti in range(num_steps):\n",
    "        x,newcases = simulator(x, data.edge_index, data.edge_attr, ti)\n",
    "    return x, newcases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc678f",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d77880",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.array([1000]*4)## populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19e8d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph\n",
    "A = np.array([[0.25 , 0.25, 0.4, 0.1 ],\n",
    "        [0.25, 0.75 , 0. , 0. ],\n",
    "        [0.4, 0. , 0.55 , 0.05],\n",
    "        [0.1 , 0 , 0.05, 0.85 ]])\n",
    "# adjacency_matrix = torch.tensor(WN)\n",
    "adjacency_matrix = torch.tensor(A)\n",
    "# Get the indices where the adjacency matrix has a non-zero value\n",
    "edge_index = torch.nonzero(adjacency_matrix, as_tuple=False).t()\n",
    "\n",
    "# If your adjacency matrix has edge weights, you can get them like this:\n",
    "edge_weight = adjacency_matrix[edge_index[0], edge_index[1]]\n",
    "\n",
    "T = 60\n",
    "N = 4\n",
    "\n",
    "# initial the states\n",
    "xx = np.zeros((N,T+2)) # number of nodes, the columns of attributes\n",
    "pop = np.array([10000]*4)\n",
    "xx[:,1] = pop ## populations\n",
    "## col_2 is the new infections generated by the new infectors\n",
    "xx[2,2] = 10 ## the new infections at time 0 \n",
    "xx = torch.tensor(xx,dtype=torch.float)\n",
    "\n",
    "data = Data(x=xx, edge_index=edge_index, edge_attr=edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b7a3a8",
   "metadata": {},
   "source": [
    "### observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e59435e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewInf_i, newcases = simulate_dynamics(data, R0=2.5, r=torch.tensor(0.1), num_steps=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5cbc287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3581)\n",
      "Step 0, Loss 2165526967.8130155\n",
      "tensor(1.3891)\n",
      "tensor(0.7877)\n",
      "tensor(0.3904)\n",
      "tensor(0.4063)\n",
      "tensor(0.9251)\n",
      "tensor(1.1400)\n",
      "tensor(2.0477)\n",
      "tensor(2.2940)\n",
      "tensor(1.2362)\n",
      "tensor(0.2183)\n",
      "Step 10, Loss 2165526972.952822\n",
      "tensor(0.0418)\n",
      "tensor(1.9328)\n",
      "tensor(0.5345)\n",
      "tensor(3.5415)\n",
      "tensor(1.3836)\n",
      "tensor(0.8554)\n",
      "tensor(1.5241)\n",
      "tensor(0.4310)\n",
      "tensor(2.3927)\n",
      "tensor(1.1017)\n",
      "Step 20, Loss 2165526972.069419\n",
      "tensor(0.4519)\n",
      "tensor(0.2568)\n",
      "tensor(1.0681)\n",
      "tensor(1.3047)\n",
      "tensor(1.0420)\n",
      "tensor(1.8428)\n",
      "tensor(0.6086)\n",
      "tensor(1.7909)\n",
      "tensor(0.2626)\n",
      "tensor(0.6176)\n",
      "Step 30, Loss 2165526972.553546\n",
      "tensor(1.3276)\n",
      "tensor(0.3676)\n",
      "tensor(1.8233)\n",
      "tensor(0.6725)\n",
      "tensor(4.2262)\n",
      "tensor(1.6161)\n",
      "tensor(0.1850)\n",
      "tensor(0.1595)\n",
      "tensor(0.1717)\n",
      "tensor(1.5802)\n",
      "Step 40, Loss 2165526971.590886\n",
      "tensor(0.3589)\n",
      "tensor(0.0135)\n",
      "tensor(3.1333)\n",
      "tensor(2.2250)\n",
      "tensor(0.5875)\n",
      "tensor(2.3238)\n",
      "tensor(0.5419)\n",
      "tensor(3.3492)\n",
      "tensor(0.5647)\n",
      "tensor(1.0156)\n",
      "Step 50, Loss 2165526972.1555433\n",
      "tensor(0.0407)\n",
      "tensor(2.5541)\n",
      "tensor(0.9631)\n",
      "tensor(0.3037)\n",
      "tensor(2.3685)\n",
      "tensor(0.6648)\n",
      "tensor(0.1746)\n",
      "tensor(1.1942)\n",
      "tensor(0.5188)\n",
      "tensor(1.0362)\n",
      "Step 60, Loss 2165526972.1349096\n",
      "tensor(1.7639)\n",
      "tensor(1.6332)\n",
      "tensor(0.3320)\n",
      "tensor(0.8205)\n",
      "tensor(1.6576)\n",
      "tensor(0.8010)\n",
      "tensor(2.3365)\n",
      "tensor(0.0428)\n",
      "tensor(0.1063)\n",
      "tensor(0.1085)\n",
      "Step 70, Loss 2165526973.0625906\n",
      "tensor(1.0256)\n",
      "tensor(0.8333)\n",
      "tensor(1.1673)\n",
      "tensor(1.5659)\n",
      "tensor(0.0272)\n",
      "tensor(1.1376)\n",
      "tensor(1.2171)\n",
      "tensor(1.0769)\n",
      "tensor(0.4805)\n",
      "tensor(0.4115)\n",
      "Step 80, Loss 2165526972.759562\n",
      "tensor(0.5912)\n",
      "tensor(0.6952)\n",
      "tensor(1.5879)\n",
      "tensor(0.8785)\n",
      "tensor(0.8419)\n",
      "tensor(2.7414)\n",
      "tensor(0.3720)\n",
      "tensor(1.1264)\n",
      "tensor(0.3136)\n",
      "tensor(0.5413)\n",
      "Step 90, Loss 2165526972.629811\n",
      "tensor(2.2317)\n",
      "tensor(1.0857)\n",
      "tensor(0.4688)\n",
      "tensor(1.2163)\n",
      "tensor(0.9573)\n",
      "tensor(0.4691)\n",
      "tensor(0.1533)\n",
      "tensor(1.3712)\n",
      "tensor(0.6672)\n"
     ]
    }
   ],
   "source": [
    "class ParameterInferenceGNNWithSimulator(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, simulator_out_channels, num_parameters):\n",
    "        super(ParameterInferenceGNNWithSimulator, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.parameter_predictor = torch.nn.Linear(hidden_channels, num_parameters)\n",
    "        self.simulator = EpidemicSimulator()  # Your EpidemicSimulator model, initialized appropriately\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.global_mean_pool(x, data.batch)\n",
    "        \n",
    "        parameters = self.parameter_predictor(x)\n",
    "        simulated_curves = self.simulator(parameters, other_required_args...)  # Adjust according to your model's requirements\n",
    "        \n",
    "        return parameters, simulated_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae8c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
