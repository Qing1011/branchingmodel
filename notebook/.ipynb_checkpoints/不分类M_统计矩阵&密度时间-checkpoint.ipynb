{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M矩阵 && density&dwell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime as d\n",
    "from datetime import datetime as D\n",
    "import matplotlib.ticker as ticker\n",
    "import random \n",
    "import time\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_02_24.csv\n",
      "2020_03_02.csv\n",
      "2020_03_09.csv\n",
      "2020_03_16.csv\n",
      "2020_03_23.csv\n",
      "2020_03_30.csv\n",
      "2020_04_06.csv\n",
      "2020_04_13.csv\n",
      "2020_04_20.csv\n",
      "2020_04_27.csv\n",
      "2020_05_04.csv\n",
      "2020_05_11.csv\n",
      "2020_05_18.csv\n",
      "2020_05_25.csv\n",
      "2020_06_01.csv\n",
      "2020_06_08.csv\n",
      "2020_06_15.csv\n",
      "2020_06_22.csv\n",
      "2020_06_29.csv\n",
      "2020_07_06.csv\n",
      "2020_07_13.csv\n",
      "2020_07_20.csv\n",
      "2020_07_27.csv\n",
      "2020_08_03.csv\n",
      "2020_08_10.csv\n",
      "2020_08_17.csv\n",
      "2020_08_24.csv\n",
      "2020_08_31.csv\n",
      "2020_09_07.csv\n",
      "2020_09_14.csv\n",
      "2020_09_21.csv\n",
      "2020_09_28.csv\n",
      "2020_10_05.csv\n",
      "2020_10_12.csv\n",
      "2020_10_19.csv\n",
      "2020_10_26.csv\n",
      "2020_11_02.csv\n",
      "2020_11_09.csv\n",
      "2020_11_16.csv\n",
      "2020_11_23.csv\n",
      "2020_11_30.csv\n",
      "2020_12_07.csv\n"
     ]
    }
   ],
   "source": [
    "data_path='/Users/jelly/Desktop/new_poi/data/'\n",
    "\n",
    "NYCdata = pd.read_excel(data_path+'uhfOrder.xlsx',usecols=['reorder','Zipcodes'],dtype='str')#postal code data\n",
    "NYCdata['Zipcodes']=NYCdata['Zipcodes'].str.split(',')\n",
    "NYCdata=NYCdata.explode(\"Zipcodes\").drop_duplicates()\n",
    "zip2UHF=pd.DataFrame(data=NYCdata['reorder'].values,index=NYCdata['Zipcodes'].values,dtype='str')#UHF index\n",
    "\n",
    "UHFdata = pd.read_excel(data_path+'CT2UHf.xlsx',usecols=['tract','UHF'],dtype='str')#cencus tract data\n",
    "tract2UHF=pd.DataFrame(data=UHFdata['UHF'].values,index=UHFdata['tract'].values,columns=['UHF'])#Cencus tract index\n",
    "\n",
    "PATH=data_path+\"02-12\"\n",
    "filenames = os.listdir(PATH)\n",
    "filenames.sort(key=lambda x: int(x.split(\".\")[0])) \n",
    "listOfDay=[]#save date in sequence\n",
    "listOfWeek=[]#save week in sequence\n",
    "dicOfDay2t={}#dictionary of date to time index\n",
    "date_format = \"%Y_%m_%d\"\n",
    "M_t=41*7+5 #M matrix statisical duration\n",
    "cluster_num=5\n",
    "M=np.zeros((M_t,42,42))\n",
    "filenum=0\n",
    "startDate='20/02/25'\n",
    "day2week={}# dictionary of day to week\n",
    "\n",
    "def Getmodify(visitorHome,visitorNum):# modify bias between effective cencus tract data  and visitor num\n",
    "    new_visitor_aray=np.zeros((visitorHome.shape[0]))\n",
    "    visitor_aray=visitorHome.values\n",
    "    homeSum=visitor_aray.sum()\n",
    "    weight=visitor_aray/homeSum\n",
    "    loss=visitorNum-homeSum\n",
    "    new_visitor_aray=visitor_aray+loss*weight\n",
    "    return new_visitor_aray\n",
    "\n",
    "for filename in filenames:\n",
    "     filenum+=1\n",
    "     print(filename)\n",
    "     week = D.strptime(filename[:10],date_format)\n",
    "     currWeekString = week.strftime('%y/%m/%d')\n",
    "     if currWeekString not in listOfWeek:# save date in sequence\n",
    "         listOfWeek.append(currWeekString)     \n",
    "     with open(os.path.join(PATH, filename), 'r', encoding=\"utf-8\") as file:\n",
    "         filereader = csv.reader(file)\n",
    "         for row_list in filereader:\n",
    "            if row_list[8]!='naics_code':\n",
    "                listCT=[]# save cencus tract name\n",
    "                listCTvisitor=[]# save visitor num\n",
    "                visitor=int(row_list[32]) \n",
    "                postalCode=str(row_list[14]) \n",
    "                destination=zip2UHF.loc[postalCode].values\n",
    "                cbgRaw=row_list[38].replace('{','').replace('}','')\n",
    "                listOfcbg=[str(i.split('\":')[0][1:12]) for i in cbgRaw.split(\",\")]\n",
    "                listOfcbgnum=[int(i.split('\":')[1]) for i in cbgRaw.split(\",\")]\n",
    "                for i in range(len(listOfcbg)):\n",
    "                    if listOfcbg[i] in list(tract2UHF.index):# check vaild cencus data \n",
    "                            listCT.append(listOfcbg[i])\n",
    "                            listCTvisitor.append(listOfcbgnum[i])\n",
    "                vitiorRaw=row_list[34].replace('[','').replace(']','')\n",
    "                listOfDailyVisitor=[int(i) for i in vitiorRaw.split(\",\")]\n",
    "                DailyVisitor=np.array(listOfDailyVisitor)\n",
    "                dailyVisitorweight=DailyVisitor/visitor\n",
    "                if len(listCTvisitor)>0:\n",
    "                    CT=pd.DataFrame(listCT,dtype='str')\n",
    "                    visitorHome=pd.DataFrame(listCTvisitor,dtype='int')\n",
    "                    modifyHomevisitor=Getmodify(visitorHome, visitor)\n",
    "                    for i in range(modifyHomevisitor.shape[0]):\n",
    "                        home=tract2UHF.loc[CT.loc[i].values].values\n",
    "                        num=modifyHomevisitor[i]*dailyVisitorweight\n",
    "                        for j in range(7):\n",
    "                            currDay = week + d.timedelta(days=j)\n",
    "                            currDayString = currDay.strftime('%y/%m/%d')\n",
    "                            if currDayString>startDate:\n",
    "                                if currDayString not in listOfDay:\n",
    "                                    listOfDay.append(currDayString)\n",
    "                                    dicOfDay2t[currDayString]=(filenum-1)*7+j-2\n",
    "                                    day2week[(filenum-1)*7+j-2]=filenum-1\n",
    "                                M[dicOfDay2t[currDayString]][int(home)][int(destination)] += num[j]\n",
    "#Smooth M                                    \n",
    "M_smooth=np.zeros((M_t,42,42))\n",
    "for t in range(M_t):\n",
    "    M_set7=M[max(0,t-3):min(M_t,t+4)]\n",
    "    M_smooth[t]=np.mean(M_set7,axis=0) \n",
    "                                     \n",
    "#normalize by NYC people num\n",
    "N_raw=pd.read_excel(data_path+'NYCpop.xlsx',usecols=['num'],dtype='int')\n",
    "N_all=N_raw.values\n",
    "M_norm=np.zeros((M_t,42,42))\n",
    "for t in range(M_t):\n",
    "    for i in range(42):\n",
    "        M_norm[t][i]=M_smooth[t][i] / N_all[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按类别限制poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020_02_24.csv\n",
      "2020_03_02.csv\n",
      "2020_03_09.csv\n",
      "2020_03_16.csv\n",
      "2020_03_23.csv\n",
      "2020_03_30.csv\n",
      "2020_04_06.csv\n",
      "2020_04_13.csv\n",
      "2020_04_20.csv\n",
      "2020_04_27.csv\n",
      "2020_05_04.csv\n",
      "2020_05_11.csv\n",
      "2020_05_18.csv\n",
      "2020_05_25.csv\n",
      "2020_06_01.csv\n",
      "2020_06_08.csv\n",
      "2020_06_15.csv\n",
      "2020_06_22.csv\n",
      "2020_06_29.csv\n",
      "2020_07_06.csv\n",
      "2020_07_13.csv\n",
      "2020_07_20.csv\n",
      "2020_07_27.csv\n",
      "2020_08_03.csv\n",
      "2020_08_10.csv\n",
      "2020_08_17.csv\n",
      "2020_08_24.csv\n",
      "2020_08_31.csv\n",
      "2020_09_07.csv\n",
      "2020_09_14.csv\n",
      "2020_09_21.csv\n",
      "2020_09_28.csv\n",
      "2020_10_05.csv\n",
      "2020_10_12.csv\n",
      "2020_10_19.csv\n",
      "2020_10_26.csv\n",
      "2020_11_02.csv\n",
      "2020_11_09.csv\n",
      "2020_11_16.csv\n",
      "2020_11_23.csv\n",
      "2020_11_30.csv\n",
      "2020_12_07.csv\n"
     ]
    }
   ],
   "source": [
    "data_path='/Users/jelly/Desktop/new_poi/data/'\n",
    "cluster_list = pd.read_excel(data_path+\"cluster5_0419.xlsx\",dtype='str')#Clustering naics_code\n",
    "naic2Cata=pd.DataFrame(data=cluster_list['cluster'].values,index=cluster_list['naics_code'].values,columns=['clustering'])#catagory index\n",
    "naicsset=pd.read_excel(data_path+\"cluster5_0419.xlsx\",dtype='str',usecols=['naics_code'])#Effective naics code set\n",
    "\n",
    "NYCdata = pd.read_excel(data_path+'uhfOrder.xlsx',usecols=['reorder','Zipcodes'],dtype='str')#postal code data\n",
    "NYCdata['Zipcodes']=NYCdata['Zipcodes'].str.split(',')\n",
    "NYCdata=NYCdata.explode(\"Zipcodes\").drop_duplicates()\n",
    "zip2UHF=pd.DataFrame(data=NYCdata['reorder'].values,index=NYCdata['Zipcodes'].values,dtype='str')#UHF index\n",
    "\n",
    "UHFdata = pd.read_excel(data_path+'CT2UHf.xlsx',usecols=['tract','UHF'],dtype='str')#cencus tract data\n",
    "tract2UHF=pd.DataFrame(data=UHFdata['UHF'].values,index=UHFdata['tract'].values,columns=['UHF'])#Cencus tract index\n",
    "\n",
    "PATH=data_path+\"02-12\"\n",
    "filenames = os.listdir(PATH)\n",
    "filenames.sort(key=lambda x: int(x.split(\".\")[0])) \n",
    "listOfDay=[]#save date in sequence\n",
    "listOfWeek=[]#save week in sequence\n",
    "dicOfDay2t={}#dictionary of date to time index\n",
    "date_format = \"%Y_%m_%d\"\n",
    "M_t=41*7+5 #M matrix statisical duration\n",
    "M=np.zeros((M_t,42,42))\n",
    "filenum=0\n",
    "startDate='20/02/25'\n",
    "day2week={}# dictionary of day to week\n",
    "\n",
    "def Getmodify(visitorHome,visitorNum):# modify bias between effective cencus tract data  and visitor num\n",
    "    new_visitor_aray=np.zeros((visitorHome.shape[0]))\n",
    "    visitor_aray=visitorHome.values\n",
    "    homeSum=visitor_aray.sum()\n",
    "    weight=visitor_aray/homeSum\n",
    "    loss=visitorNum-homeSum\n",
    "    new_visitor_aray=visitor_aray+loss*weight\n",
    "    return new_visitor_aray\n",
    "\n",
    "for filename in filenames:\n",
    "     filenum+=1\n",
    "     print(filename)\n",
    "     week = D.strptime(filename[:10],date_format)\n",
    "     currWeekString = week.strftime('%y/%m/%d')\n",
    "     if currWeekString not in listOfWeek:# save date in sequence\n",
    "         listOfWeek.append(currWeekString)     \n",
    "     with open(os.path.join(PATH, filename), 'r', encoding=\"utf-8\") as file:\n",
    "         filereader = csv.reader(file)\n",
    "         for row_list in filereader:\n",
    "             listCT=[]# save cencus tract name\n",
    "             listCTvisitor=[]# save visitor num\n",
    "             if len(row_list[8])>=4 and row_list[8]!='naics_code':\n",
    "                 naicsCode=row_list[8][0:4]\n",
    "                 if naicsCode in naicsset.values:\n",
    "                     visitor=int(row_list[32]) \n",
    "                     postalCode=str(row_list[14]) \n",
    "                     destination=zip2UHF.loc[postalCode].values\n",
    "                     catagory=naic2Cata.loc[naicsCode].values\n",
    "                     cbgRaw=row_list[38].replace('{','').replace('}','')\n",
    "                     listOfcbg=[str(i.split('\":')[0][1:12]) for i in cbgRaw.split(\",\")]\n",
    "                     listOfcbgnum=[int(i.split('\":')[1]) for i in cbgRaw.split(\",\")]\n",
    "                     for i in range(len(listOfcbg)):\n",
    "                         if listOfcbg[i] in list(tract2UHF.index):# check vaild cencus data \n",
    "                                 listCT.append(listOfcbg[i])\n",
    "                                 listCTvisitor.append(listOfcbgnum[i])\n",
    "                     vitiorRaw=row_list[34].replace('[','').replace(']','')\n",
    "                     listOfDailyVisitor=[int(i) for i in vitiorRaw.split(\",\")]\n",
    "                     DailyVisitor=np.array(listOfDailyVisitor)\n",
    "                     dailyVisitorweight=DailyVisitor/visitor\n",
    "                     if len(listCTvisitor)>0:\n",
    "                         CT=pd.DataFrame(listCT,dtype='str')\n",
    "                         visitorHome=pd.DataFrame(listCTvisitor,dtype='int')\n",
    "                         modifyHomevisitor=Getmodify(visitorHome, visitor)\n",
    "                         for i in range(modifyHomevisitor.shape[0]):\n",
    "                             home=tract2UHF.loc[CT.loc[i].values].values\n",
    "                             num=modifyHomevisitor[i]*dailyVisitorweight\n",
    "                             for j in range(7):\n",
    "                                currDay = week + d.timedelta(days=j)\n",
    "                                currDayString = currDay.strftime('%y/%m/%d')\n",
    "                                if currDayString>startDate:\n",
    "                                    if currDayString not in listOfDay:\n",
    "                                        listOfDay.append(currDayString)\n",
    "                                        dicOfDay2t[currDayString]=(filenum-1)*7+j-2\n",
    "                                        day2week[(filenum-1)*7+j-2]=filenum-1\n",
    "                                    M[dicOfDay2t[currDayString]][int(home)][int(destination)] += num[j]\n",
    "                                  \n",
    "#Smooth M                                    \n",
    "M_smooth=np.zeros((M_t,42,42))\n",
    "for t in range(M_t):\n",
    "    M_set7=M[max(0,t-3):min(M_t,t+4)]\n",
    "    M_smooth[t]=np.mean(M_set7,axis=0) \n",
    "                                     \n",
    "#normalize by NYC people num\n",
    "N_raw=pd.read_excel(data_path+'NYCpop.xlsx',usecols=['num'],dtype='int')\n",
    "N_all=N_raw.values\n",
    "M_norm=np.zeros((M_t,42,42))\n",
    "for t in range(M_t):\n",
    "    for i in range(42):\n",
    "        M_norm[t][i]=M_smooth[t][i] / N_all[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 密度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as D\n",
    "dicOfPlaceWeekVisitor={}#save POI visitor (week uhf catagory poi)\n",
    "dicOfWeekDwell={}#save POI dwell\n",
    "dictionaryOfArea={}# save POI area\n",
    "filenames = os.listdir(PATH)\n",
    "filenames.sort(key=lambda x: int(x.split(\".\")[0])) \n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    week = D.strptime(filename[:10], date_format)\n",
    "    currWeekString = week.strftime('%y/%m/%d')\n",
    "    with open(os.path.join(PATH, filename), 'r', encoding=\"utf-8\") as file:\n",
    "        filereader = csv.reader(file)\n",
    "        for row_list in filereader:\n",
    "            if len(row_list[8])>=4 and row_list[8]!='naics_code':\n",
    "                visitor=int(row_list[32])\n",
    "                poi=row_list[0]\n",
    "                dwell_time=float(row_list[42])\n",
    "                postalCode=str(row_list[14]) \n",
    "                uhf=int(zip2UHF.loc[postalCode].values)\n",
    "\n",
    "                if currWeekString not in dicOfPlaceWeekVisitor:\n",
    "                    dicOfPlaceWeekVisitor[currWeekString]={}\n",
    "                    dicOfPlaceWeekVisitor[currWeekString][uhf]={}\n",
    "                    dicOfPlaceWeekVisitor[currWeekString][uhf][poi]=visitor\n",
    "\n",
    "                    dicOfWeekDwell[currWeekString]={}\n",
    "                    dicOfWeekDwell[currWeekString][uhf]={}\n",
    "                    dicOfWeekDwell[currWeekString][uhf][poi]=dwell_time\n",
    "                else:\n",
    "                    if uhf not in dicOfPlaceWeekVisitor[currWeekString]:\n",
    "                        dicOfPlaceWeekVisitor[currWeekString][uhf]={}\n",
    "                        dicOfPlaceWeekVisitor[currWeekString][uhf][poi]=visitor\n",
    "                            \n",
    "                        dicOfWeekDwell[currWeekString][uhf]={}\n",
    "                        dicOfWeekDwell[currWeekString][uhf][poi]=dwell_time\n",
    "                    else:\n",
    "                        if poi not in dicOfPlaceWeekVisitor[currWeekString][uhf]:\n",
    "                            dicOfPlaceWeekVisitor[currWeekString][uhf][poi]=visitor\n",
    "                            dicOfWeekDwell[currWeekString][uhf][poi]=dwell_time\n",
    "                        else:\n",
    "                            dicOfPlaceWeekVisitor[currWeekString][uhf][poi]+=visitor\n",
    "                            dicOfWeekDwell[currWeekString][uhf][poi]+=dwell_time\n",
    "                            print('data repeat')\n",
    "     \n",
    "                area=int(row_list[29])\n",
    "                if poi not in dictionaryOfArea:\n",
    "                    dictionaryOfArea[poi]=area \n",
    "\n",
    "WeekDensity=np.zeros((filenum,42))\n",
    "WeekDwell=np.zeros((filenum,42))                                \n",
    "\n",
    "for k in range(len(listOfWeek)):\n",
    "    t=listOfWeek[k]\n",
    "    for i in range(42):\n",
    "        listOfDensity=[]\n",
    "        for poi in dicOfPlaceWeekVisitor[t][i]:\n",
    "            d=dicOfPlaceWeekVisitor[t][i][poi]/dictionaryOfArea[poi]#poi density\n",
    "            listOfDensity.append(d)\n",
    "        densityMean=sum(listOfDensity)/len(listOfDensity)# uhf mean density    \n",
    "        dwellRaw=list(dicOfWeekDwell[t][i].values())\n",
    "        dwellMean=sum(dwellRaw)/len(dwellRaw)#uhf mean dwell                    \n",
    "        WeekDensity[k][i]=densityMean/7\n",
    "        WeekDwell[k][i]=dwellMean\n",
    "   \n",
    "\n",
    "# smooth & normalize\n",
    "smooth_dwell=np.zeros((filenum,42))\n",
    "smooth_density=np.zeros((filenum,42))\n",
    "for t in range(filenum):\n",
    "    dwell_set7=WeekDwell[max(0,t-3):min(M_t,t+4)]\n",
    "    smooth_dwell[t]=np.mean(dwell_set7,axis=0) \n",
    "    density_set7=WeekDensity[max(0,t-3):min(M_t,t+4)]\n",
    "    smooth_density[t]=np.mean(density_set7,axis=0) \n",
    "dwell=smooth_dwell/np.max(smooth_dwell)\n",
    "density=smooth_density/np.max(smooth_density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f6 = open(\"/Users/jelly/Desktop/new_poi/data/unsort_03-12_14_1/dict_day2week\",'w')\n",
    "f6.write(str(day2week))\n",
    "f6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jelly/Desktop/new_poi/data/unsort_03-12_14_1/M_normal.txt', 'w') as outfile:\n",
    "    for i in M_norm:\n",
    "        np.savetxt(outfile, i, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jelly/Desktop/new_poi/data/03-12_14data/density.txt', 'w') as outfile:\n",
    "    for i in density:\n",
    "        np.savetxt(outfile, i, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jelly/Desktop/new_poi/data/03-12_14data/dwell.txt', 'w') as outfile:\n",
    "    for i in dwell:\n",
    "        np.savetxt(outfile, i, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
