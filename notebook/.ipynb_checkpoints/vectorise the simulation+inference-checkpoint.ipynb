{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c15771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f0967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WN = np.loadtxt('W_avg.csv')\n",
    "pop = np.loadtxt('pop_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80650951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpidemicSimulator(MessagePassing):\n",
    "    def __init__(self, r, p, weight, max_time_step):\n",
    "        super(EpidemicSimulator, self).__init__(aggr='add')\n",
    "        self.r = r\n",
    "#         self.p = p\n",
    "        self.p_prime = 1-p\n",
    "        self.max_time_step = max_time_step\n",
    "        self.Z = 3 # latent period\n",
    "        self.Zb = 1 # scale parameter for Z\n",
    "        self.D = 5 # infectious period\n",
    "        self.Db = 1 # scale parameter for beta\n",
    "        self.weight = torch.Tensor(weight)\n",
    "        self.offspring = []\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, step):\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x, edge_attr=edge_attr, step=step)\n",
    "\n",
    "    def message(self, x_j, edge_index, edge_attr, step):\n",
    "        # x_j has shape [E, num_features]\n",
    "        # edge_attr has shape [E, num_edge_features]\n",
    "        # Get the new infections from x_j.\n",
    "        new_infectors = x_j[:, 2+step:3+step] ## the infectors at time ti\n",
    "        temp = new_infectors.round().int()\n",
    "        cases = temp.squeeze().tolist()\n",
    "        # Initialize an empty tensor to store the results\n",
    "        results = torch.zeros_like(new_infectors)\n",
    "        # Generate negative binomial for each size\n",
    "        for i, size in enumerate(cases):\n",
    "#             print(size)\n",
    "            if size>0:\n",
    "                offspring_per_case = torch.distributions.Categorical(self.weight).sample(sample_shape=torch.Size([size]))\n",
    "            #torch.distributions.negative_binomial.NegativeBinomial(self.r,self.p_prime).sample(sample_shape=torch.Size([size]))\n",
    "                self.offspring.extend(offspring_per_case.tolist())\n",
    "                temp_sum = offspring_per_case.sum()\n",
    "            else:\n",
    "                temp_sum = 0\n",
    "#             print(temp_sum)\n",
    "            results[i] = temp_sum\n",
    "        ######^^^^^^#######\n",
    "        # Compute the messages.\n",
    "        messages = results * edge_attr.view(-1, 1)\n",
    "        return messages\n",
    "\n",
    "    def update(self, aggr_out, x, step):\n",
    "        # x has shape [N, num_features], it is the original node features\n",
    "        # The new infections are the aggregated messages.\n",
    "        new_infections = aggr_out # aggr_out has shape [N, 1], it contains the updated infections\n",
    "        #### Add the effective infections to the column corresponding to the current step.####\n",
    "        ## immu first\n",
    "        population = x[:, 1:2]\n",
    "        total_infection = torch.sum(x[:, 2:3+step], dim=1,keepdim=True) \n",
    "        rate = (population - total_infection) / population # Compute the rate.\n",
    "        rate[rate<0] = 0\n",
    "        \n",
    "        new_effective_infections = new_infections*rate\n",
    "        new_infections_int  = new_effective_infections.round().int()\n",
    "        ### diffuse the new_infections to different times \n",
    "        inf_sizes = new_infections_int.squeeze().tolist()\n",
    "        for i, inf_size_i in enumerate(inf_sizes):\n",
    "            gamma_dist1 = torch.distributions.Gamma(self.Z, 1/self.Zb)\n",
    "            gamma_dist2 = torch.distributions.Gamma(self.D, 1/self.Db)\n",
    "            latency_p = gamma_dist1.rsample(sample_shape=torch.Size([inf_size_i]))\n",
    "            infectious_p = gamma_dist2.rsample(sample_shape=torch.Size([inf_size_i]))\n",
    "            v = torch.rand(inf_size_i)\n",
    "            delay_days = latency_p + v * infectious_p\n",
    "#             print(step, delay_days)\n",
    "            for j,delay_t in enumerate(delay_days):\n",
    "                t_j = (3+step+delay_t).ceil().int()\n",
    "                if t_j > self.max_time_step:\n",
    "                    pass\n",
    "                else:\n",
    "                    x[i,t_j] = x[i,t_j] + 1\n",
    "        ######^^^^^^#######\n",
    "        # The rest of the features remain the same.\n",
    "        other_features = x[:, 2:].clone()\n",
    "        # Concatenate the new infections, the population, and the other features to get the new node features.\n",
    "        x_new = torch.cat([new_infections.clone(), population, other_features], dim=1)\n",
    "        return x_new, self.offspring\n",
    "\n",
    "def simulate_dynamics(data, R0, r, num_steps):\n",
    "    p = r/(R0+r)  \n",
    "    xx = np.arange(0,100,1)  # define the range of x values the cutoff is 200\n",
    "#     pmf = SSA.nbinom.pmf(xx, r, p)  # calculate the probability mass function\n",
    "    pmf = SSA.nbinom.pmf(xx, r.detach().numpy(), p.detach().numpy())\n",
    "    weights_n = pmf/np.sum(pmf)\n",
    "    x = data.x\n",
    "    T_len = data.x.shape[1]\n",
    "    simulator = EpidemicSimulator(r,p, weights_n, max_time_step=(T_len-1))\n",
    "    for ti in range(num_steps):\n",
    "        x,newcases = simulator(x, data.edge_index, data.edge_attr, ti)\n",
    "    return x, newcases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc678f",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d77880",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.array([1000]*4)## populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19e8d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph\n",
    "A = np.array([[0.25 , 0.25, 0.4, 0.1 ],\n",
    "        [0.25, 0.75 , 0. , 0. ],\n",
    "        [0.4, 0. , 0.55 , 0.05],\n",
    "        [0.1 , 0 , 0.05, 0.85 ]])\n",
    "# adjacency_matrix = torch.tensor(WN)\n",
    "adjacency_matrix = torch.tensor(A)\n",
    "# Get the indices where the adjacency matrix has a non-zero value\n",
    "edge_index = torch.nonzero(adjacency_matrix, as_tuple=False).t()\n",
    "\n",
    "# If your adjacency matrix has edge weights, you can get them like this:\n",
    "edge_weight = adjacency_matrix[edge_index[0], edge_index[1]]\n",
    "\n",
    "T = 60\n",
    "N = 4\n",
    "\n",
    "# initial the states\n",
    "xx = np.zeros((N,T+2)) # number of nodes, the columns of attributes\n",
    "pop = np.array([10000]*4)\n",
    "xx[:,1] = pop ## populations\n",
    "## col_2 is the new infections generated by the new infectors\n",
    "xx[2,2] = 10 ## the new infections at time 0 \n",
    "xx = torch.tensor(xx,dtype=torch.float)\n",
    "\n",
    "data = Data(x=xx, edge_index=edge_index, edge_attr=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6949f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 60])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a427c87",
   "metadata": {},
   "source": [
    "### observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc0b4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewInf_i, newcases = simulate_dynamics(data, R0=2.5, r=0.1, num_steps=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd46380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Obeserved_data = Data(x=NewInf_i, edge_index=edge_index, edge_attr=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38f20149",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m svi\u001b[38;5;241m.\u001b[39mstep(observed_data)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_and_grads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguide, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_trace, guide_trace \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_particle \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/infer/elbo.py:237\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_particles):\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_trace(model, guide, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[38;5;241m=\u001b[39m get_importance_trace(\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_plate_nesting, model, guide, args, kwargs\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/infer/enum.py:65\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[38;5;241m.\u001b[39mdetach_()\n\u001b[0;32m---> 65\u001b[0m     model_trace \u001b[38;5;241m=\u001b[39m poutine\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[1;32m     66\u001b[0m         poutine\u001b[38;5;241m.\u001b[39mreplay(model, trace\u001b[38;5;241m=\u001b[39mguide_trace), graph_type\u001b[38;5;241m=\u001b[39mgraph_type\n\u001b[1;32m     67\u001b[0m     )\u001b[38;5;241m.\u001b[39mget_trace(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     70\u001b[0m     check_model_guide_match(model_trace, guide_trace, max_plate_nesting)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsngr\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_INPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.11/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_context_wrap\u001b[39m(context, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[42], line 19\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     16\u001b[0m r \u001b[38;5;241m=\u001b[39m pyro\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, pyro\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mNormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Simulate dynamics with the sampled r\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m simulated_data, _ \u001b[38;5;241m=\u001b[39m simulate_dynamics(data\u001b[38;5;241m=\u001b[39mdata, R0\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.5\u001b[39m, r\u001b[38;5;241m=\u001b[39mr, num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Apply the function F\u001b[39;00m\n\u001b[1;32m     22\u001b[0m transformed_simulated_data \u001b[38;5;241m=\u001b[39m simulated_data[:,\u001b[38;5;241m2\u001b[39m:]\n",
      "Cell \u001b[0;32mIn[30], line 86\u001b[0m, in \u001b[0;36msimulate_dynamics\u001b[0;34m(data, R0, r, num_steps)\u001b[0m\n\u001b[1;32m     84\u001b[0m pmf \u001b[38;5;241m=\u001b[39m SSA\u001b[38;5;241m.\u001b[39mnbinom\u001b[38;5;241m.\u001b[39mpmf(xx, r\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), p\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     85\u001b[0m weights_n \u001b[38;5;241m=\u001b[39m pmf\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(pmf)\n\u001b[0;32m---> 86\u001b[0m x \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m     87\u001b[0m T_len \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     88\u001b[0m simulator \u001b[38;5;241m=\u001b[39m EpidemicSimulator(r,p, weights_n, max_time_step\u001b[38;5;241m=\u001b[39m(T_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import torch\n",
    "from pyro import poutine\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.distributions import constraints\n",
    "\n",
    "\n",
    "\n",
    "def model(initial_conditions, data):\n",
    "    # Prior on r\n",
    "    r = pyro.sample(\"r\", pyro.distributions.Uniform(0, 10))  \n",
    "    \n",
    "    # Simulate dynamics with the sampled r\n",
    "    simulated_data, _ = simulate_dynamics(data=initial_conditions, R0=2.5, r=r, num_steps=60)\n",
    "    \n",
    "    # Apply the function F\n",
    "    transformed_simulated_data = simulated_data[:,2:]\n",
    "    \n",
    "    # Likelihood\n",
    "    pyro.sample(\"obs\", pyro.distributions.Normal(transformed_simulated_data, 0.1), obs=data.x)\n",
    "\n",
    "def guide(data):\n",
    "    # Variational parameters for r\n",
    "    r_loc = pyro.param(\"r_loc\", torch.tensor(0.))\n",
    "    r_scale = pyro.param(\"r_scale\", torch.tensor(1.), constraint=constraints.positive)\n",
    "    \n",
    "    # Sample r\n",
    "    r = pyro.sample(\"r\", pyro.distributions.Normal(r_loc, r_scale))\n",
    "    return r\n",
    "\n",
    "# Data: This should be the observed data\n",
    "observed_data = NewInf_i[:,2:]\n",
    "\n",
    "# SVI\n",
    "svi = SVI(model, guide, Adam({\"lr\": 0.001}), loss=Trace_ELBO())\n",
    "initial_states = data\n",
    "\n",
    "num_steps = 5000\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(initial_states, observed_data)\n",
    "    if step % 100 == 0:\n",
    "        print(f\"Step {step}, Loss {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f52d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
