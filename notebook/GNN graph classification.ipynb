{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c3e3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat, savemat\n",
    "import pandas as pd\n",
    "import scipy.special as SS\n",
    "import scipy.stats as SSA\n",
    "import copy\n",
    "import math\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import os\n",
    "import numpy.linalg as LA\n",
    "import gzip\n",
    "\n",
    "# load pickle module\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df23db",
   "metadata": {},
   "source": [
    "The observation is \n",
    "3142 x 60 \n",
    "\n",
    "we can i) treat 3142 nodes and 60 features of each nodes \n",
    "\n",
    "(or 60 nodes 3142 features of the each nodes)\n",
    "\n",
    "In this case the mobility data is the graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63942ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(MatrixClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_features)\n",
    "        self.classifier = Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # Use GCN layers to update node features\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Use global mean pooling to get a representation of the whole graph\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "\n",
    "        # Use a linear layer to classify the graph\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32473492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nodes (rows of the matrix)\n",
    "num_nodes = 4\n",
    "\n",
    "# Number of features per node (columns of the matrix)\n",
    "num_features = 2\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2\n",
    "\n",
    "# Create a random matrix\n",
    "matrix = torch.randn(num_nodes, num_features)\n",
    "\n",
    "# Create a fully connected graph\n",
    "edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j]).t().contiguous()\n",
    "\n",
    "\n",
    "# Create a random target class\n",
    "y = torch.randint(num_classes, (1,))\n",
    "\n",
    "# Create a data object\n",
    "data = Data(x=matrix, edge_index=edge_index, y=y)\n",
    "\n",
    "# Create a model and an optimizer\n",
    "model = MatrixClassifier(num_features, num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95147115",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([random.randint(0, 1)], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0bd7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold our Data objects\n",
    "dataset = []\n",
    "\n",
    "# Assume we have 10 graphs with the same structure for this example\n",
    "for _ in range(10):\n",
    "    # Each graph is associated with a random target (0 or 1)\n",
    "    y = torch.tensor([random.randint(0, 1)], dtype=torch.long)\n",
    "    \n",
    "    # Create a Data object for each graph\n",
    "    data = Data(x=matrix, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Add the Data object to our list\n",
    "    dataset.append(data)\n",
    "\n",
    "# Now we can create a DataLoader\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11d2b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7218454480171204\n",
      "Epoch: 2, Loss: 0.6985946893692017\n",
      "Epoch: 3, Loss: 0.6829551458358765\n",
      "Epoch: 4, Loss: 0.6747191548347473\n",
      "Epoch: 5, Loss: 0.6731728315353394\n",
      "Epoch: 6, Loss: 0.6762601733207703\n",
      "Epoch: 7, Loss: 0.6803207397460938\n",
      "Epoch: 8, Loss: 0.682461142539978\n",
      "Epoch: 9, Loss: 0.6821051836013794\n",
      "Epoch: 10, Loss: 0.6800498366355896\n",
      "Epoch: 11, Loss: 0.6774061918258667\n",
      "Epoch: 12, Loss: 0.6750756502151489\n",
      "Epoch: 13, Loss: 0.6735717058181763\n",
      "Epoch: 14, Loss: 0.6730198860168457\n",
      "Epoch: 15, Loss: 0.6732522249221802\n",
      "Epoch: 16, Loss: 0.6739424467086792\n",
      "Epoch: 17, Loss: 0.6747397184371948\n",
      "Epoch: 18, Loss: 0.6753655672073364\n",
      "Epoch: 19, Loss: 0.6756609082221985\n",
      "Epoch: 20, Loss: 0.6755892038345337\n",
      "Epoch: 21, Loss: 0.67521071434021\n",
      "Epoch: 22, Loss: 0.6746443510055542\n",
      "Epoch: 23, Loss: 0.6740313768386841\n",
      "Epoch: 24, Loss: 0.6735018491744995\n",
      "Epoch: 25, Loss: 0.6731492280960083\n",
      "Epoch: 26, Loss: 0.6730135679244995\n",
      "Epoch: 27, Loss: 0.6730775833129883\n",
      "Epoch: 28, Loss: 0.6732746958732605\n",
      "Epoch: 29, Loss: 0.6735129952430725\n",
      "Epoch: 30, Loss: 0.6737030744552612\n",
      "Epoch: 31, Loss: 0.6737848520278931\n",
      "Epoch: 32, Loss: 0.6737414598464966\n",
      "Epoch: 33, Loss: 0.6735973358154297\n",
      "Epoch: 34, Loss: 0.6734031438827515\n",
      "Epoch: 35, Loss: 0.6732158064842224\n",
      "Epoch: 36, Loss: 0.6730796098709106\n",
      "Epoch: 37, Loss: 0.6730164289474487\n",
      "Epoch: 38, Loss: 0.6730237007141113\n",
      "Epoch: 39, Loss: 0.6730801463127136\n",
      "Epoch: 40, Loss: 0.6731559038162231\n",
      "Epoch: 41, Loss: 0.6732212901115417\n",
      "Epoch: 42, Loss: 0.6732560396194458\n",
      "Epoch: 43, Loss: 0.673252284526825\n",
      "Epoch: 44, Loss: 0.6732138991355896\n",
      "Epoch: 45, Loss: 0.6731545925140381\n",
      "Epoch: 46, Loss: 0.6730920076370239\n",
      "Epoch: 47, Loss: 0.6730421781539917\n",
      "Epoch: 48, Loss: 0.6730154156684875\n",
      "Epoch: 49, Loss: 0.6730139255523682\n",
      "Epoch: 50, Loss: 0.6730318069458008\n",
      "Epoch: 51, Loss: 0.6730583906173706\n",
      "Epoch: 52, Loss: 0.673082172870636\n",
      "Epoch: 53, Loss: 0.673093855381012\n",
      "Epoch: 54, Loss: 0.6730905771255493\n",
      "Epoch: 55, Loss: 0.67307448387146\n",
      "Epoch: 56, Loss: 0.6730520129203796\n",
      "Epoch: 57, Loss: 0.6730307340621948\n",
      "Epoch: 58, Loss: 0.673016369342804\n",
      "Epoch: 59, Loss: 0.6730116009712219\n",
      "Epoch: 60, Loss: 0.6730155944824219\n",
      "Epoch: 61, Loss: 0.6730244159698486\n",
      "Epoch: 62, Loss: 0.6730338931083679\n",
      "Epoch: 63, Loss: 0.6730397343635559\n",
      "Epoch: 64, Loss: 0.6730402708053589\n",
      "Epoch: 65, Loss: 0.673035740852356\n",
      "Epoch: 66, Loss: 0.6730281114578247\n",
      "Epoch: 67, Loss: 0.6730200052261353\n",
      "Epoch: 68, Loss: 0.6730141639709473\n",
      "Epoch: 69, Loss: 0.6730116605758667\n",
      "Epoch: 70, Loss: 0.6730127930641174\n",
      "Epoch: 71, Loss: 0.6730160117149353\n",
      "Epoch: 72, Loss: 0.673019528388977\n",
      "Epoch: 73, Loss: 0.6730219721794128\n",
      "Epoch: 74, Loss: 0.6730220913887024\n",
      "Epoch: 75, Loss: 0.6730201244354248\n",
      "Epoch: 76, Loss: 0.673017144203186\n",
      "Epoch: 77, Loss: 0.6730140447616577\n",
      "Epoch: 78, Loss: 0.6730122566223145\n",
      "Epoch: 79, Loss: 0.6730116605758667\n",
      "Epoch: 80, Loss: 0.673012375831604\n",
      "Epoch: 81, Loss: 0.6730137467384338\n",
      "Epoch: 82, Loss: 0.6730149984359741\n",
      "Epoch: 83, Loss: 0.6730155944824219\n",
      "Epoch: 84, Loss: 0.6730153560638428\n",
      "Epoch: 85, Loss: 0.6730142831802368\n",
      "Epoch: 86, Loss: 0.6730130910873413\n",
      "Epoch: 87, Loss: 0.6730121374130249\n",
      "Epoch: 88, Loss: 0.6730117797851562\n",
      "Epoch: 89, Loss: 0.6730117797851562\n",
      "Epoch: 90, Loss: 0.6730121970176697\n",
      "Epoch: 91, Loss: 0.6730128526687622\n",
      "Epoch: 92, Loss: 0.6730132102966309\n",
      "Epoch: 93, Loss: 0.6730130910873413\n",
      "Epoch: 94, Loss: 0.6730128526687622\n",
      "Epoch: 95, Loss: 0.6730123162269592\n",
      "Epoch: 96, Loss: 0.6730118989944458\n",
      "Epoch: 97, Loss: 0.6730116605758667\n",
      "Epoch: 98, Loss: 0.6730117201805115\n",
      "Epoch: 99, Loss: 0.6730118989944458\n",
      "Epoch: 100, Loss: 0.6730120182037354\n"
     ]
    }
   ],
   "source": [
    "# 假设 `dataset` 是一个图的列表\n",
    "# loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 设定训练的epoch数量\n",
    "num_epochs = 100\n",
    "\n",
    "# Training loop\n",
    "# for epoch in range(100):\n",
    "#     optimizer.zero_grad()\n",
    "#     out = model(data)\n",
    "#     loss = F.nll_loss(out, data.y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in loader:\n",
    "        # batch是一个Batch对象，包含了批量图的数据\n",
    "        batch_data, batch_target = batch.x, batch.y\n",
    "\n",
    "        # 如果你使用GPU，需要将数据移动到GPU\n",
    "#         batch_data, batch_target = batch_data.to(device), batch_target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        output = model(batch)  # 前向计算\n",
    "        loss = F.nll_loss(output, batch_target)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "544454a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f128854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e7da177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87d665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
