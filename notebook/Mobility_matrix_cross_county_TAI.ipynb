{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34e4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import datetime as d\n",
    "from datetime import datetime as D\n",
    "import matplotlib.ticker as ticker\n",
    "import random \n",
    "import time\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import gzip\n",
    "import sys\n",
    "import datetime\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ed4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../../../../../../Volumes/Seagate_Qing/Safegraph/'\n",
    "save_dir = '../../../../../../../Volumes/Seagate_Qing/Safegraph_clean/'\n",
    "years = ['2020','2021','2022']\n",
    "months = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "#np.save('ym_datesofweek',ym_datesofweek)\n",
    "ym_datesofweek = np.load('ym_datesofweek.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9e63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "US_states = pd.read_csv('us-state-ansi-fips.csv')\n",
    "state_lists_0 = US_states.stusps.values\n",
    "state_lists = [s[1:] for s in state_lists_0]\n",
    "state_lists.remove('HI')\n",
    "state_lists.remove('AK') ### remove the non mainland\n",
    "real_data_path = '/Users/qingyao/OneDrive - cumc.columbia.edu/machine_learning_data/'\n",
    "fips_main = pd.read_csv(real_data_path+'county_data/fips_mainland.csv',names=['FIPS'])\n",
    "fips_main_sorted = fips_main.sort_values(by='FIPS')\n",
    "fips_main_sorted['poi_idx'] = fips_main_sorted.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0048a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.field_size_limit(500 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa519d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['raw_visit_counts', 'visits_by_day', 'poi_cbg',\n",
       "       'visitor_home_aggregation'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_header = pd.read_csv('header.csv')\n",
    "df_header.iloc[[32,34,36,38],0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1c6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_header = ['raw_visit_counts', 'visits_by_day', 'poi_cbg','visitor_home_aggregation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee216687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### preprocess extract all the nan data\n",
    "y = '2020'\n",
    "for m in ['03']:\n",
    "    print('month:', m)\n",
    "    subdir = data_path + y + '/' + m + '/'\n",
    "    week_start_dates = ym_datesofweek[y + m]\n",
    "    for start_day in week_start_dates[:1]:\n",
    "        print(start_day)\n",
    "        weekly_folder = data_path + y + '/' + m + '/' + start_day + '/SAFEGRAPH/WP/'\n",
    "        for i in range(1,30):  ### there are 40 files !!!\n",
    "            file_name = weekly_folder + 'core_poi-geometry-patterns-part{}.csv.gz'.format(i)\n",
    "            file_stat = os.stat(file_name)\n",
    "            print(i)\n",
    "            count = 0\n",
    "            actual = 0\n",
    "            new_name = save_dir + y + '_' + m + '_' + start_day + '_{}.csv'.format(i)\n",
    "            with open(new_name, 'w', encoding='utf-8', newline='') as csv_out_file:  # Open the file for writing (not appending)\n",
    "                filewriter = csv.writer(csv_out_file)\n",
    "                filewriter.writerow(selected_header)  # Write the header once for each new file\n",
    "                with gzip.open(file_name, 'rt') as csv_in_file:\n",
    "                    filereader = csv.reader(csv_in_file)\n",
    "                    for row_list in filereader:\n",
    "                        count = count + 1\n",
    "                        if (row_list[13] in state_lists) and (row_list[28] == 'US') and (row_list[34] != '') and (row_list[36] != '') and (row_list[38] != '{}'):  ### select us mainland first\n",
    "                            actual = actual+1\n",
    "                            filewriter.writerow([row_list[32], row_list[34], row_list[36], row_list[38]])\n",
    "            print(actual/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4f7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../codes/mobility_matrix_extraction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f037962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month: 03\n",
      "02\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "#### extract the M\n",
    "y = '2020'\n",
    "for m in ['03']:\n",
    "    print('month:', m)\n",
    "    subdir = data_path + y + '/' + m + '/'\n",
    "    week_start_dates = ym_datesofweek[y + m]\n",
    "    for start_day in week_start_dates[:1]:\n",
    "        print(start_day)\n",
    "        weekly_folder = subdir + start_day + '/SAFEGRAPH/WP/'\n",
    "        M_w = np.zeros((7,3108,3108)) #M_weekly = np.zeros((7,3108,3108)) ## \n",
    "        for i in range(1,2):  ### there are 40 files !!!\n",
    "            print(i)\n",
    "            new_name = save_dir + y + '_' + m + '_' + start_day + '_{}.csv'.format(i)\n",
    "            df_file = pd.read_csv(new_name)\n",
    "            df_file['poi_fips'] = df_file['poi_cbg'].astype(str).str[:-7].astype(int)\n",
    "            df_i = pd.merge(df_file,fips_main_sorted,left_on='poi_fips',right_on='FIPS',how='left') \n",
    "            df_i_main = df_i.dropna()\n",
    "            df_i_main['visits_by_day_list'] = df_i_main['visits_by_day'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "            df_i_main['multiplier'] = df_i_main.apply(lambda x: x['visits_by_day_list']/x['raw_visit_counts'], axis=1) ### multiplier\n",
    "            df_i_main['visitor_home_list'] = df_i_main['visitor_home_aggregation'].apply(lambda x: x[1:-1].replace('\"','').split(','))\n",
    "            df_i_main[['home_idx_list', 'modified_visit_list']] = df_i_main.apply(lambda x: process_visitor_data(x['visitor_home_list'],x['raw_visit_counts'],fips_main_sorted),axis=1)\n",
    "            df_i_main['vis_daily_matrix'] = df_i_main.apply(lambda x: dayvisits_by_visitor(x['modified_visit_list'], x['multiplier']),axis=1)\n",
    "            for j_data_idx in range(len(df_i_main)):\n",
    "                df_j = df_i_main.iloc[j_data_idx]\n",
    "                M_w = mobility_extract_per_poi(df_j, M_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfd28d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Getmodify(visitorHome,visitorNum):# modify bias between effective cencus tract data  and visitor num\n",
    "    new_visitor_aray = np.zeros((visitorHome.shape[0]))\n",
    "    visitor_aray = visitorHome.values\n",
    "    homeSum = visitor_aray.sum()\n",
    "    weight = visitor_aray/homeSum\n",
    "    loss = visitorNum - homeSum\n",
    "    new_visitor_aray = visitor_aray + loss*weight\n",
    "    return new_visitor_aray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac511b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month: 03\n",
      "02\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "#### extract the M\n",
    "y = '2020'\n",
    "for m in ['03']:\n",
    "    print('month:', m)\n",
    "    subdir = data_path + y + '/' + m + '/'\n",
    "    week_start_dates = ym_datesofweek[y + m]\n",
    "    for start_day in week_start_dates[:1]:\n",
    "        print(start_day)\n",
    "        weekly_folder = subdir + start_day + '/SAFEGRAPH/WP/'\n",
    "        M_weekly = np.zeros((7,3108,3108)) ## \n",
    "        for i in range(1,2):  ### there are 40 files !!!\n",
    "            print(i)\n",
    "            new_name = save_dir + y + '_' + m + '_' + start_day + '_{}.csv'.format(i)\n",
    "            with open(new_name, 'r', encoding='utf-8', newline='') as csv_in_file:  # Open the file for writing (not appending)\n",
    "                filereader = csv.reader(csv_in_file)\n",
    "                next(filereader)  # Skip the header (first row)\n",
    "                for row_list in filereader:\n",
    "                    destination = np.int64(row_list[2][:-7]) \n",
    "                    destination_idx = fips_main_sorted[fips_main_sorted['FIPS'] == destination].index.values[0]\n",
    "#                     print('poi_idx', destination_idx)\n",
    "                    listCT=[]# save cencus tract name\n",
    "                    listCTvisitor=[]# save visitor num\n",
    "        \n",
    "                    visitor = int(row_list[0]) #raw_visit_counts\n",
    "                    vitiorRaw = row_list[1].replace('[','').replace(']','')\n",
    "                    listOfDailyVisitor = [int(i) for i in vitiorRaw.split(\",\")]\n",
    "                    \n",
    "                    DailyVisitor = np.array(listOfDailyVisitor)\n",
    "                    dailyVisitorweight = DailyVisitor/visitor\n",
    "                    \n",
    "                    cbgRaw=row_list[3].replace('{','').replace('}','')\n",
    "                    \n",
    "                    filtered_cbgRaw = [item for item in cbgRaw.replace('\"','').split(',') if not item.startswith('CA:')]\n",
    "\n",
    "                    listOfcbg=[str(i.split(':')[0]) for i in filtered_cbgRaw]\n",
    "                    listOfcbgnum=[int(i.split(':')[1]) for i in filtered_cbgRaw]\n",
    "                    for i in range(len(listOfcbg)): ### for every home\n",
    "                        listCT.append(listOfcbg[i])\n",
    "                        listCTvisitor.append(listOfcbgnum[i])\n",
    "\n",
    "                    CT = pd.DataFrame(listCT,dtype='str') ## make them the dataframe cbgs county fips\n",
    "                    visitorHome = pd.DataFrame(listCTvisitor,dtype='int') ### numbers\n",
    "                    modifyHomevisitor = Getmodify(visitorHome, visitor)\n",
    "                    \n",
    "                    for i, modified_visitor_count in enumerate(modifyHomevisitor):\n",
    "                        home_location = CT.iloc[i][0]\n",
    "                        home_county = np.int64(home_location[:-6])\n",
    "                        visitor_count_by_day = modified_visitor_count * dailyVisitorweight\n",
    "#                         print (home_county, visitor_count_by_day)\n",
    "                        if home_county in fips_main_sorted['FIPS'].values and destination in fips_main_sorted['FIPS'].values:\n",
    "                            home_idx = fips_main_sorted[fips_main_sorted['FIPS'] == home_county].index[0]\n",
    "                            destination_idx = fips_main_sorted[fips_main_sorted['FIPS'] == destination].index[0]\n",
    "                            for d in range(7):\n",
    "                                M_weekly[d, destination_idx, home_idx] += visitor_count_by_day[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbd2e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "for i in range(1000000):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf925a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize by  people num\n",
    "pop = np.loadtxt('pop_sorted.csv')\n",
    "M_norm = M_weekly / pop[np.newaxis, :, np.newaxis]\n",
    "for d in range(7):\n",
    "    np.savetxt(save_dir+'M_{}{}.csv'.format(y,m), M_weekly[0],delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth M                                    \n",
    "# M_smooth=np.zeros((M_t,42,42))\n",
    "# for t in range(M_t):\n",
    "#     M_set7=M[max(0,t-3):min(M_t,t+4)]\n",
    "#     M_smooth[t]=np.mean(M_set7,axis=0) \n",
    "                                     \n",
    "#normalize by  people num\n",
    "N_raw=pd.read_excel(data_path+'NYCpop.xlsx',usecols=['num'],dtype='int')\n",
    "N_all=N_raw.values\n",
    "M_norm=np.zeros((M_t,42,42))\n",
    "for t in range(M_t):\n",
    "    for i in range(42):\n",
    "        M_norm[t][i]=M_smooth[t][i] / N_all[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
